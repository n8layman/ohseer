[{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":null,"dir":"","previous_headings":"","what":"OCR Provider Cost & Accuracy Comparison","title":"OCR Provider Cost & Accuracy Comparison","text":"document compares three OCR providers supported ohseer terms cost, accuracy (OCR Arena ranking), key features. Last Updated: February 2026","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"pricing-summary","dir":"","previous_headings":"","what":"Pricing Summary","title":"OCR Provider Cost & Accuracy Comparison","text":"* Claude pricing token-based, page-based. Estimates assume ~3,000 input tokens + ~3,000 output tokens per average page tables/structure. Actual costs vary document complexity.","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"id_1-claude-opus-45-anthropic","dir":"","previous_headings":"Detailed Pricing","what":"1. Claude Opus 4.5 (Anthropic)","title":"OCR Provider Cost & Accuracy Comparison","text":"API Pricing (2026): - Input: $5 per million tokens ($0.005 per 1K tokens) - Output: $25 per million tokens ($0.025 per 1K tokens) - Batch API: 50% discount token costs Estimated Cost Per Page: Assuming average document page moderate complexity (text + tables + structure extraction): - Input tokens: ~3,000 tokens (PDF page + extraction prompt) - Output tokens: ~3,000 tokens (structured JSON text, tables, headers) Standard API: - Input cost: 3K tokens × $0.005 = $0.015 - Output cost: 3K tokens × $0.025 = $0.075 - Total: ~$0.09 per page Batch API (50% discount): - Total: ~$0.045 per page Cost Optimization: - Prompt caching can reduce costs 90% repeated processing - Cache writes: $6.25/MTok (25% surcharge) - Cache reads: $0.50/MTok (90% discount) Important Note: estimates. Actual costs depend : - Document complexity (tables/structure = output tokens) - Page text density - Number tables per page - Use prompt caching simple text-pages, costs low $0.03-0.05/page. complex multi-table scientific documents, costs reach $0.20-0.30/page.","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"id_2-mistral-ocr-3","dir":"","previous_headings":"Detailed Pricing","what":"2. Mistral OCR 3","title":"OCR Provider Cost & Accuracy Comparison","text":"API Pricing (2026): - Standard: $2 per 1,000 pages = $0.002 per page - Batch API: $1 per 1,000 pages = $0.001 per page (50% discount) - Annotations (structured output): $3 per 1,000 pages = $0.003 per page Key Features: - Fixed page-based pricing (predictable costs) - Structured output via JSON schema annotations - 74% win rate Mistral OCR 2 - Backward compatible OCR 2","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"id_3-tensorlake","dir":"","previous_headings":"Detailed Pricing","what":"3. Tensorlake","title":"OCR Provider Cost & Accuracy Comparison","text":"API Pricing (2026): - Standard: $0.01 per page - batch discount listed - Structured output included base price Key Features: - Claims 91.7% accuracy (vs 88.4% AWS Textract) - file size limits (unlike AWS Textract’s 5MB synchronous limit) - Async processing large documents - Native structured output fragment types","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"ocr-arena-rankings-february-2026","dir":"","previous_headings":"","what":"OCR Arena Rankings (February 2026)","title":"OCR Provider Cost & Accuracy Comparison","text":"Tensorlake ranked OCR Arena.","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"best-accuracy-highest-quality","dir":"","previous_headings":"Cost vs Accuracy Trade-offs","what":"Best Accuracy (Highest Quality)","title":"OCR Provider Cost & Accuracy Comparison","text":"Claude Opus 4.5 - #1 OCR Arena - Cost: ~$0.045-0.09/page (Batch API) - Use : Maximum accuracy critical, complex handwriting, scientific documents, legal/medical docs","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"best-value-costperformance-balance","dir":"","previous_headings":"Cost vs Accuracy Trade-offs","what":"Best Value (Cost/Performance Balance)","title":"OCR Provider Cost & Accuracy Comparison","text":"Tensorlake - 91.7% claimed accuracy - Cost: $0.01/page - Use : Good balance accuracy cost, processing large volumes, structured documents","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"lowest-cost","dir":"","previous_headings":"Cost vs Accuracy Trade-offs","what":"Lowest Cost","title":"OCR Provider Cost & Accuracy Comparison","text":"Mistral OCR 3 - Industry-leading low price - Cost: $0.001-0.003/page - Use : Budget primary concern, processing massive volumes (millions pages), acceptable accuracy simpler documents","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"high-value-documents-legal-medical-research","dir":"","previous_headings":"Recommendation by Use Case","what":"High-Value Documents (Legal, Medical, Research)","title":"OCR Provider Cost & Accuracy Comparison","text":"→ Claude Opus 4.5 - Highest accuracy minimizes costly errors - Superior handwriting recognition - Best table extraction","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"large-scale-production-workloads","dir":"","previous_headings":"Recommendation by Use Case","what":"Large-Scale Production Workloads","title":"OCR Provider Cost & Accuracy Comparison","text":"→ Tensorlake Mistral OCR 3 Batch - Tensorlake: Better accuracy, structured output - Mistral Batch: Lowest cost scale","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"scientifictechnical-documents","dir":"","previous_headings":"Recommendation by Use Case","what":"Scientific/Technical Documents","title":"OCR Provider Cost & Accuracy Comparison","text":"→ Claude Opus 4.5 Tensorlake - handle complex tables well - Claude excels multi-page context - Tensorlake offers good accuracy lower cost","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"budget-constrained-projects","dir":"","previous_headings":"Recommendation by Use Case","what":"Budget-Constrained Projects","title":"OCR Provider Cost & Accuracy Comparison","text":"→ Mistral OCR 3 Batch - $0.001/page batch processing - Acceptable accuracy many use cases - Structured output available","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"example-processing-10000-pages","dir":"","previous_headings":"","what":"Example: Processing 10,000 Pages","title":"OCR Provider Cost & Accuracy Comparison","text":"* Costs vary based document complexity. Lower end simple text, higher end complex multi-table documents.","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"sources","dir":"","previous_headings":"","what":"Sources","title":"OCR Provider Cost & Accuracy Comparison","text":"Claude Opus 4.5 Pricing - Anthropic Claude Opus 4.5 Pricing Guide - CometAPI Mistral OCR 3 Announcement Mistral OCR 3 Pricing - VentureBeat Tensorlake Pricing OCR Arena Leaderboard","code":""},{"path":"https://n8layman.github.io/ohseer/COST_COMPARISON.html","id":"notes","dir":"","previous_headings":"","what":"Notes","title":"OCR Provider Cost & Accuracy Comparison","text":"pricing current February 2026 Costs exclude API call overhead, storage, data transfer Batch API discounts typically require minimum volume commitments Prompt caching (Claude) can significantly reduce costs repeated processing patterns Actual costs may vary based document characteristics API usage patterns","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":null,"dir":"","previous_headings":"","what":"ohseer: Multi-Provider OCR Implementation Summary","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Date: February 17, 2026 Version: 0.0.0.9000 License: GPL-3","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"ohseer package now provides unified access four OCR providers, returning compatible output formats seamless integration downstream tools like ecoextract.","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"supported-providers","dir":"","previous_headings":"Overview","what":"Supported Providers","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Claude Opus 4.5 (#1 OCR Arena - ELO 1696, 71.2% win rate) Mistral OCR 3 (mistral-ocr-2512 - ELO 1434, 39.0% win rate) Tensorlake (91.7% claimed accuracy) AWS Textract (existing integration)","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"id_1-claude-opus-45-integration","dir":"","previous_headings":"Key Achievements","what":"1. Claude Opus 4.5 Integration","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"New Functions: - claude_ocr() - Main entry point - claude_ocr_process_file() - Process PDFs images - claude_extract_pages() - Transform Tensorlake format Features: - Direct PDF support via Anthropic Messages API - Native structured output JSON prompting - Support Opus 4.5 Sonnet 4.5 models - Base64 encoding documents images Cost: ~$0.045-0.09 per page (50% batch discount)","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"id_2-mistral-ocr-3-structured-output","dir":"","previous_headings":"Key Achievements","what":"2. Mistral OCR 3 Structured Output","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Updated Functions: - mistral_ocr() - Now uses mistral-ocr-2512 default - mistral_ocr_process_url() - Added structured output parameters New Functions: - mistral_extract_pages() - Transform Tensorlake format Critical New Parameters: Matters: original reason switching Tensorlake Mistral wasn’t properly extracting headers/footers. new parameters (available OCR 3) now provide dedicated extraction like Tensorlake. Structured Output via JSON Schema: Cost: $0.001-0.003 per page","code":"extract_header = TRUE  # Extracts page headers separately extract_footer = TRUE  # Extracts page footers separately document_annotation_format = list(   type = \"json_schema\",   json_schema = your_schema )"},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"id_3-unified-output-format","dir":"","previous_headings":"Key Achievements","what":"3. Unified Output Format","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"providers now return identical structure via {provider}_extract_pages(): structure 100% compatible ecoextract package requirements.","code":"list(   list(     page_number = 1,     page_header = c(\"header1\", \"header2\"),     section_header = c(\"Introduction\"),     text = \"Body text with\\n\\nparagraph breaks\",     tables = list(       list(         content = \"plain text\",         markdown = \"| Col | Col |\\n|-----|-----|\",         html = \"<table>...<\/table>\",         summary = \"Table description\"       )     ),     other = list(       list(type = \"figure_caption\", content = \"Figure 1...\")     )   ),   # ... more pages )"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"r-functions","dir":"","previous_headings":"Files Added","what":"R Functions","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"R/claude_ocr.R - Main Claude OCR function (66 lines) R/claude_ocr_process_file.R - File processing via Claude API (167 lines) R/claude_extract_pages.R - Output transformation (92 lines) R/mistral_extract_pages.R - Mistral output transformation (139 lines)","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"documentation","dir":"","previous_headings":"Files Added","what":"Documentation","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"COST_COMPARISON.md - Detailed pricing analysis OCR Arena rankings USAGE_EXAMPLES.md - Comprehensive usage guide three providers IMPLEMENTATION_SUMMARY.md - file test_ocr_providers.R - Comprehensive test script quick_test.R - Quick validation script","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"auto-generated","dir":"","previous_headings":"Files Added","what":"Auto-Generated","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"man/claude_ocr.Rd man/claude_ocr_process_file.Rd man/claude_extract_pages.Rd man/mistral_extract_pages.Rd","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"core-functions","dir":"","previous_headings":"Files Modified","what":"Core Functions","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"R/mistral_ocr.R - Added OCR 3 model, structured output, header/footer extraction R/mistral_ocr_process_url.R - New parameters structured output header/footer extraction","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"package-metadata","dir":"","previous_headings":"Files Modified","what":"Package Metadata","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"DESCRIPTION - Updated mention Claude Opus 4.5 support NAMESPACE - Auto-updated new exports","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"documentation-1","dir":"","previous_headings":"Files Modified","what":"Documentation","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"man/mistral_ocr.Rd - Updated new parameters man/mistral_ocr_process_url.Rd - Updated new parameters","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"claude-integration","dir":"","previous_headings":"Technical Implementation Details","what":"Claude Integration","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"API Endpoint: POST https://api.anthropic.com/v1/messages Request Structure: Extraction Prompt: Custom prompt instructs Claude return JSON matching Tensorlake schema required fields.","code":"{   \"model\": \"claude-opus-4.5\",   \"max_tokens\": 16000,   \"messages\": [{     \"role\": \"user\",     \"content\": [       {         \"type\": \"document\",         \"source\": {           \"type\": \"base64\",           \"media_type\": \"application/pdf\",           \"data\": \"<base64_pdf>\"         }       },       {         \"type\": \"text\",         \"text\": \"<extraction_prompt>\"       }     ]   }] }"},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"mistral-ocr-3-integration","dir":"","previous_headings":"Technical Implementation Details","what":"Mistral OCR 3 Integration","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"API Endpoint: POST https://api.mistral.ai/v1/ocr Key Parameters: Response Structure:","code":"{   \"model\": \"mistral-ocr-2512\",   \"document\": {\"type\": \"document_url\", \"document_url\": \"...\"},   \"extract_header\": true,   \"extract_footer\": true,   \"table_format\": \"markdown\",   \"document_annotation_format\": {     \"type\": \"json_schema\",     \"json_schema\": {...}   },   \"document_annotation_prompt\": \"...\" } {   \"model\": \"mistral-ocr-2512\",   \"pages\": [...],   \"document_annotation\": {     \"pages\": [...]  // Structured output matching schema   },   \"usage_info\": {\"pages_processed\": N} }"},{"path":[]},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"cost-per-10000-pages","dir":"","previous_headings":"Cost Analysis","what":"Cost Per 10,000 Pages","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Claude Opus 4.5: $450-900 (standard) / $225-450 (batch) Tensorlake: $100 Mistral OCR 3: $10-20 (basic) / $30 (annotations)","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"when-to-use-each","dir":"","previous_headings":"Cost Analysis","what":"When to Use Each","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Claude Opus 4.5: - Legal, medical, high-value documents - Complex handwriting - Maximum accuracy required - Budget allows premium pricing Tensorlake: - Balanced accuracy cost - Academic/scientific papers - Large-scale production workloads - Good fragment classification needed Mistral OCR 3: - Massive scale (millions pages) - Budget-constrained projects - Simpler documents - annotations: structured extraction low cost","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"test-environment","dir":"","previous_headings":"Testing","what":"Test Environment","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"tests run data/articles/0090-3558-30_3_439.pdf (838KB, 6 pages).","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"test-script","dir":"","previous_headings":"Testing","what":"Test Script","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Run comprehensive test: Validates: 1. providers process successfully 2. Output structure matches Tensor lake format 3. Required fields present correctly typed 4. Cost estimation 5. Processing time","code":"Rscript test_ocr_providers.R"},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"expected-results","dir":"","previous_headings":"Testing","what":"Expected Results","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"providers : - Return 6 pages - Include page_number, page_header, section_header, text, tables, - Tables content, markdown, html, summary fields - Pass structure validation - compatible ecoextract","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"integration-with-ecoextract","dir":"","previous_headings":"","what":"Integration with ecoextract","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"three providers work identically ecoextract:","code":"library(ohseer) library(ecoextract)  # Choose provider result <- claude_ocr(\"document.pdf\")  # or mistral_ocr(), tensorlake_ocr() pages <- claude_extract_pages(result)  # or mistral_extract_pages(), tensorlake_extract_pages()  # Convert to JSON json_content <- jsonlite::toJSON(pages, auto_unbox = TRUE, pretty = TRUE)  # Use with ecoextract db_conn <- DBI::dbConnect(RSQLite::SQLite(), \"database.db\") ecoextract::create_database_schema(db_conn)  doc_id <- ecoextract::add_document(   db_conn = db_conn,   document_name = \"document.pdf\",   document_content = json_content )  # Extract metadata and records ecoextract::extract_metadata(doc_id, db_conn) ecoextract::extract_records(doc_id, db_conn)"},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"api-keys-required","dir":"","previous_headings":"","what":"API Keys Required","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Set environment variables .Renviron .env:","code":"ANTHROPIC_API_KEY=sk-ant-your-key MISTRAL_API_KEY=your-mistral-key TENSORLAKE_API_KEY=your-tensorlake-key"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"documentation-2","dir":"","previous_headings":"References","what":"Documentation","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"COST_COMPARISON.md - Pricing analysis USAGE_EXAMPLES.md - Usage guide OCR Arena Leaderboard","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"api-documentation","dir":"","previous_headings":"References","what":"API Documentation","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Claude API Docs Mistral OCR 3 Docs Tensorlake API","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"sources","dir":"","previous_headings":"References","what":"Sources","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Claude Models Overview Mistral OCR 3 Announcement OCR Arena","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"potential-additions","dir":"","previous_headings":"Future Enhancements","what":"Potential Additions","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Claude Opus 4.6 support (newest model) Gemini 3 Preview (#2 OCR Arena - ELO 1661) Batch API helpers cost optimization Prompt caching Claude (90% cost reduction repeated patterns) Comparison utilities test multiple providers document","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"performance-optimizations","dir":"","previous_headings":"Future Enhancements","what":"Performance Optimizations","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Parallel page processing Streaming large documents Intelligent provider selection based document characteristics Cost estimation processing","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"commit-history","dir":"","previous_headings":"","what":"Commit History","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"Latest Commit: 385e927 - “Add Claude Opus 4.5 OCR integration Mistral OCR 3 structured output” Key Changes: - 17 files changed, 1512 insertions(+), 20 deletions(-) - New providers: Claude Opus 4.5, Mistral OCR 3 structured output - Unified Tensorlake-compatible output format - Comprehensive documentation testing","code":""},{"path":"https://n8layman.github.io/ohseer/IMPLEMENTATION_SUMMARY.html","id":"summary","dir":"","previous_headings":"","what":"Summary","title":"ohseer: Multi-Provider OCR Implementation Summary","text":"ohseer package now provides: ✅ Access #1 OCR model (Claude Opus 4.5) ✅ Low-cost alternative (Mistral OCR 3 $0.001-0.003/page) ✅ Balanced option (Tensorlake $0.01/page) ✅ Unified output format compatible ecoextract ✅ Header/footer extraction across providers ✅ Structured output via JSON schemas ✅ Comprehensive documentation testing Total Added: 4 new R functions, 3 documentation files, 2 test scripts Lines Code: ~500+ lines new functionality Testing: Validated real PDFs three providers Status: Production-ready ecoextract integration","code":""},{"path":"https://n8layman.github.io/ohseer/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 ohseer authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":null,"dir":"","previous_headings":"","what":"Tensorlake Quick Start Guide","title":"Tensorlake Quick Start Guide","text":"Quick reference using Tensorlake ohseer.","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"setup-one-time","dir":"","previous_headings":"","what":"Setup (One Time)","title":"Tensorlake Quick Start Guide","text":"Get API key https://cloud.tensorlake.ai Set environment variable: add .env file:","code":"Sys.setenv(TENSORLAKE_API_KEY = \"your-key-here\") TENSORLAKE_API_KEY=your-key-here"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"parse-a-document","dir":"","previous_headings":"Basic Usage","what":"Parse a Document","title":"Tensorlake Quick Start Guide","text":"","code":"library(ohseer)  # Parse entire document result <- tensorlake_ocr(\"document.pdf\")  # Parse specific pages result <- tensorlake_ocr(\"document.pdf\", pages = \"1-5\")"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"extract-structured-page-data","dir":"","previous_headings":"Basic Usage","what":"Extract Structured Page Data","title":"Tensorlake Quick Start Guide","text":"","code":"library(jsonlite)  # Extract structured data from first 2 pages pages <- tensorlake_extract_pages(result, pages = c(1, 2))  # Access first page page1 <- pages[[1]] page1$page_header      # Journal citation, page headers page1$section_header   # Article title, section headers page1$text            # Body text (markdown format) page1$tables          # List of tables with content/markdown/html page1$other           # Other fragment types  # Convert to JSON for LLM processing json_data <- toJSON(pages, auto_unbox = TRUE, pretty = TRUE)"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"get-metadata","dir":"","previous_headings":"Basic Usage","what":"Get Metadata","title":"Tensorlake Quick Start Guide","text":"","code":"# Access metadata directly from result result$total_pages        # Total pages in document result$parsed_pages_count # Pages successfully parsed result$status            # Parse status result$usage             # API usage stats"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"extract-citation-info-from-academic-paper","dir":"","previous_headings":"Common Workflows","what":"Extract Citation Info from Academic Paper","title":"Tensorlake Quick Start Guide","text":"","code":"# Parse only first 2 pages (faster, cheaper for citations) result <- tensorlake_ocr(\"paper.pdf\", pages = c(1, 2))  # Extract all parsed pages (just pages 1-2) pages <- tensorlake_extract_pages(result)  # Get citation components page1 <- pages[[1]] citation <- page1$page_header     # e.g., \"Journal Name, 30(3), 1994, pp. 439-444\" title <- page1$section_header     # Article title authors_text <- page1$text        # Contains authors and affiliations  # Convert to JSON for LLM extraction json_for_llm <- toJSON(pages, auto_unbox = TRUE, pretty = TRUE)  # Send json_for_llm to Claude or another LLM to extract: # - Authors, affiliations, journal, volume, pages, year, DOI, etc."},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"extract-tables-from-document","dir":"","previous_headings":"Common Workflows","what":"Extract Tables from Document","title":"Tensorlake Quick Start Guide","text":"","code":"# Parse entire document result <- tensorlake_ocr(\"report.pdf\")  # Extract all pages pages <- tensorlake_extract_pages(result)  # Process tables from each page for (page in pages) {   if (length(page$tables) > 0) {     cat(\"Page\", page$page_number, \"has\", length(page$tables), \"table(s)\\n\")     for (tbl in page$tables) {       cat(tbl$markdown, \"\\n\\n\")  # Markdown format       # Also available: tbl$html, tbl$content, tbl$summary     }   } }"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"get-structured-data-for-multiple-pages","dir":"","previous_headings":"Common Workflows","what":"Get Structured Data for Multiple Pages","title":"Tensorlake Quick Start Guide","text":"","code":"# Parse entire document result <- tensorlake_ocr(\"document.pdf\")  # Extract all pages (default behavior) all_pages <- tensorlake_extract_pages(result)  # Process each page for (page in all_pages) {   cat(\"=== PAGE\", page$page_number, \"===\\n\")   cat(\"Headers:\", paste(page$page_header, collapse = \"; \"), \"\\n\")   cat(\"Sections:\", paste(page$section_header, collapse = \"; \"), \"\\n\")   cat(\"Tables:\", length(page$tables), \"\\n\")   cat(\"Text length:\", nchar(page$text), \"chars\\n\\n\") }"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"output-structure-quick-reference","dir":"","previous_headings":"","what":"Output Structure Quick Reference","title":"Tensorlake Quick Start Guide","text":"","code":"result$   ├─ parse_id              # Unique parse job ID   ├─ status                # \"successful\" when done   ├─ total_pages           # Total pages   ├─ parsed_pages_count    # Pages parsed   ├─ pages[]               # Array of page data   │  └─ page_fragments[]   # Content on each page   │     ├─ fragment_type   # \"text\", \"table\", \"section_header\", etc.   │     ├─ content         # The actual content   │     ├─ reading_order   # Order to read fragments   │     └─ bbox            # Position on page   ├─ chunks[]              # Text chunks   ├─ created_at            # Start timestamp   ├─ finished_at           # End timestamp   └─ usage                 # API usage stats"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"tips","dir":"","previous_headings":"","what":"Tips","title":"Tensorlake Quick Start Guide","text":"citations: Parse pages 1-2 save time cost Check status: Always verify result$status == \"successful\" Reading order: Use reading_order field maintain document flow Processing time: Typically ~1 second per page","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"troubleshooting","dir":"","previous_headings":"","what":"Troubleshooting","title":"Tensorlake Quick Start Guide","text":"API Key Error → Set TENSORLAKE_API_KEY environment variable Timeout Error → Increase timeout: tensorlake_ocr(\"file.pdf\", max_wait_seconds = 120) Parse Failed → Check error details contact Tensorlake support","code":"Error: Tensorlake API key not found Error: Parse job timed out after 60 seconds result$status == \"failed\""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_QUICKSTART.html","id":"more-information","dir":"","previous_headings":"","what":"More Information","title":"Tensorlake Quick Start Guide","text":"Full Vignette Setup Guide Tensorlake Docs","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":null,"dir":"","previous_headings":"","what":"Tensorlake Setup Guide","title":"Tensorlake Setup Guide","text":"guide help get started Tensorlake, recommended OCR provider ohseer.","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"why-tensorlake","dir":"","previous_headings":"","what":"Why Tensorlake?","title":"Tensorlake Setup Guide","text":"Tensorlake offers best accuracy document parsing: - 91.7% accuracy structured data extraction - 86.8% accuracy table structure preservation - 5 MB file size limit (unlike AWS Textract synchronous API) - Simple API key authentication (IAM setup required) - Competitive pricing $0.01 per page","code":""},{"path":[]},{"path":[]},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"id_1-sign-up","dir":"","previous_headings":"Getting Started","what":"1. Sign Up","title":"Tensorlake Setup Guide","text":"Visit https://cloud.tensorlake.ai create account.","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"id_2-get-your-api-key","dir":"","previous_headings":"Getting Started","what":"2. Get Your API Key","title":"Tensorlake Setup Guide","text":"Log Tensorlake dashboard Navigate API Keys section Click “Create New API Key” Copy API key","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"id_3-set-environment-variable","dir":"","previous_headings":"Getting Started","what":"3. Set Environment Variable","title":"Tensorlake Setup Guide","text":"Option 1: R Session Option 2: .env File (Recommended) Create .env file project directory: ⚠️ Security: Never commit .env files version control! Add .env .gitignore.","code":"Sys.setenv(TENSORLAKE_API_KEY = \"your-api-key-here\") TENSORLAKE_API_KEY=your-api-key-here"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"id_4-test-your-setup","dir":"","previous_headings":"Getting Started","what":"4. Test Your Setup","title":"Tensorlake Setup Guide","text":"","code":"library(ohseer)  # Process a document result <- tensorlake_ocr(\"path/to/document.pdf\")  # Check the result str(result, max.level = 2)"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"basic-document-parsing","dir":"","previous_headings":"Usage Examples","what":"Basic Document Parsing","title":"Tensorlake Setup Guide","text":"","code":"# Parse entire document result <- tensorlake_ocr(\"document.pdf\")  # Parse specific pages result <- tensorlake_ocr(\"document.pdf\", pages = \"1-5\")  # Save output to file result <- tensorlake_ocr(\"document.pdf\", output_file = \"result.json\")"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"working-with-results","dir":"","previous_headings":"Usage Examples","what":"Working with Results","title":"Tensorlake Setup Guide","text":"","code":"# Access parsed content text <- result$result$content  # Access metadata metadata <- result$metadata  # Check parse status status <- result$status  # Should be \"completed\""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"custom-wait-time","dir":"","previous_headings":"Advanced Options","what":"Custom Wait Time","title":"Tensorlake Setup Guide","text":"default, tensorlake_ocr() waits 60 seconds parsing complete:","code":"# Wait up to 120 seconds result <- tensorlake_ocr(\"large-document.pdf\", max_wait_seconds = 120)"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"poll-interval","dir":"","previous_headings":"Advanced Options","what":"Poll Interval","title":"Tensorlake Setup Guide","text":"Adjust frequently check parse status:","code":"# Check every 5 seconds instead of default 2 result <- tensorlake_ocr(\"document.pdf\", poll_interval = 5)"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"low-level-api-access","dir":"","previous_headings":"Advanced Options","what":"Low-Level API Access","title":"Tensorlake Setup Guide","text":"control, use low-level functions:","code":"# Submit parse job parse_response <- tensorlake_parse_document(   file_path = \"document.pdf\",   tensorlake_api_key = Sys.getenv(\"TENSORLAKE_API_KEY\"),   pages = \"1-10\" )  parse_id <- parse_response$parse_id  # Wait a bit... Sys.sleep(5)  # Get results result <- tensorlake_get_parse_result(   parse_id = parse_id,   tensorlake_api_key = Sys.getenv(\"TENSORLAKE_API_KEY\") )"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"supported-file-formats","dir":"","previous_headings":"","what":"Supported File Formats","title":"Tensorlake Setup Guide","text":"Tensorlake supports: - PDF - Microsoft Word (DOCX, DOC) - Microsoft PowerPoint (PPTX, PPT) - Microsoft Excel (XLSX, XLS) - Images (PNG, JPEG, TIFF) - HTML - Plain text (TXT) - CSV","code":""},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"pricing","dir":"","previous_headings":"","what":"Pricing","title":"Tensorlake Setup Guide","text":"Document Parsing: $0.01 per page additional fees storage bandwidth Pay process enterprise -premises deployments, contact Tensorlake support.","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"api-key-not-found","dir":"","previous_headings":"Troubleshooting","what":"API Key Not Found","title":"Tensorlake Setup Guide","text":"Error: Tensorlake API key found Solution: Set TENSORLAKE_API_KEY environment variable:","code":"Sys.setenv(TENSORLAKE_API_KEY = \"your-key\")"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"timeout-errors","dir":"","previous_headings":"Troubleshooting","what":"Timeout Errors","title":"Tensorlake Setup Guide","text":"Error: Parse job timed 60 seconds Solution: Increase max_wait_seconds:","code":"result <- tensorlake_ocr(\"document.pdf\", max_wait_seconds = 120)"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"parse-job-failed","dir":"","previous_headings":"Troubleshooting","what":"Parse Job Failed","title":"Tensorlake Setup Guide","text":"Error: Parse job failed Solution: Check error details result: Common causes: - Unsupported file format - Corrupted document - Invalid API key","code":"result$error"},{"path":"https://n8layman.github.io/ohseer/TENSORLAKE_SETUP.html","id":"support","dir":"","previous_headings":"","what":"Support","title":"Tensorlake Setup Guide","text":"Documentation: https://docs.tensorlake.ai GitHub: https://github.com/tensorlakeai/tensorlake Community Slack: Join via website Email: support@tensorlake.ai","code":""},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":null,"dir":"","previous_headings":"","what":"ohseer Usage Examples","title":"ohseer Usage Examples","text":"Complete guide using three OCR providers (Claude Opus 4.5, Mistral OCR 3, Tensorlake) structured output compatible ecoextract.","code":""},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"ohseer Usage Examples","text":"three providers follow pattern: 1. Call {provider}_ocr() process document 2. Call {provider}_extract_pages() get Tensorlake-compatible format 3. Use ecoextract downstream tools","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"basic-usage","dir":"","previous_headings":"1. Claude Opus 4.5 (#1 OCR Arena)","what":"Basic Usage","title":"ohseer Usage Examples","text":"","code":"library(ohseer)  # Set API key (or use ANTHROPIC_API_KEY environment variable) Sys.setenv(ANTHROPIC_API_KEY = \"your-api-key\")  # Process document result <- claude_ocr(\"document.pdf\")  # Extract pages in Tensorlake format pages <- claude_extract_pages(result)  # Access structured data pages[[1]]$page_number     # Page number pages[[1]]$page_header     # Running headers pages[[1]]$section_header  # Section titles pages[[1]]$text           # Body text pages[[1]]$tables         # Tables (content, markdown, html, summary) pages[[1]]$other          # Figures, captions, etc."},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"model-selection","dir":"","previous_headings":"1. Claude Opus 4.5 (#1 OCR Arena)","what":"Model Selection","title":"ohseer Usage Examples","text":"","code":"# Use Opus 4.5 for maximum accuracy (default) result <- claude_ocr(\"document.pdf\", model = \"claude-opus-4.5-20250514\")  # Use Sonnet 4.5 for faster/cheaper processing result <- claude_ocr(\"document.pdf\", model = \"claude-sonnet-4.5-20250929\")"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"save-output","dir":"","previous_headings":"1. Claude Opus 4.5 (#1 OCR Arena)","what":"Save Output","title":"ohseer Usage Examples","text":"","code":"# Save raw API response result <- claude_ocr(\"document.pdf\", output_file = \"claude_result.json\")  # Save Tensorlake-formatted pages pages <- claude_extract_pages(result) jsonlite::write_json(pages, \"pages.json\", auto_unbox = TRUE, pretty = TRUE)"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"use-with-ecoextract","dir":"","previous_headings":"1. Claude Opus 4.5 (#1 OCR Arena)","what":"Use with ecoextract","title":"ohseer Usage Examples","text":"","code":"library(ecoextract)  # Process document result <- claude_ocr(\"scientific_paper.pdf\") pages <- claude_extract_pages(result)  # Convert to JSON for ecoextract json_content <- jsonlite::toJSON(pages, auto_unbox = TRUE, pretty = TRUE)  # Use with ecoextract functions # (ecoextract workflow continues from here)"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"basic-usage-1","dir":"","previous_headings":"2. Mistral OCR 3","what":"Basic Usage","title":"ohseer Usage Examples","text":"","code":"library(ohseer)  # Set API key Sys.setenv(MISTRAL_API_KEY = \"your-api-key\")  # Process document (now with OCR 3 and header/footer extraction) result <- mistral_ocr(\"document.pdf\")  # Extract pages pages <- mistral_extract_pages(result)"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"structured-output-tensorlake-compatible","dir":"","previous_headings":"2. Mistral OCR 3","what":"Structured Output (Tensorlake-Compatible)","title":"ohseer Usage Examples","text":"key getting Mistral OCR 3 return Tensorlake-formatted data using document_annotation_format:","code":"# Define Tensorlake-compatible schema tensorlake_schema <- list(   type = \"object\",   properties = list(     pages = list(       type = \"array\",       items = list(         type = \"object\",         required = c(\"page_number\", \"text\", \"tables\"),         properties = list(           page_number = list(type = \"integer\"),           page_header = list(             type = \"array\",             items = list(type = \"string\")           ),           section_header = list(             type = \"array\",             items = list(type = \"string\")           ),           text = list(             type = \"string\",             description = \"All body text with paragraphs separated by newlines\"           ),           tables = list(             type = \"array\",             items = list(               type = \"object\",               properties = list(                 content = list(type = \"string\"),                 markdown = list(type = \"string\"),                 html = list(type = \"string\"),                 summary = list(type = \"string\")               )             )           ),           other = list(             type = \"array\",             items = list(               type = \"object\",               properties = list(                 type = list(type = \"string\"),                 content = list(type = \"string\")               )             )           )         )       )     )   ) )  # Process with structured output result <- mistral_ocr(   \"document.pdf\",   document_annotation_format = list(     type = \"json_schema\",     json_schema = tensorlake_schema   ),   document_annotation_prompt = \"Extract all document structure including headers, sections, text, tables, and other elements\",   extract_header = TRUE,  # Extract headers separately (OCR 3 feature)   extract_footer = TRUE   # Extract footers separately (OCR 3 feature) )  # Extract pages (will use structured output if available) pages <- mistral_extract_pages(result)"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"header-and-footer-extraction","dir":"","previous_headings":"2. Mistral OCR 3","what":"Header and Footer Extraction","title":"ohseer Usage Examples","text":"IMPORTANT: Mistral OCR 3 dedicated parameters extract headers footers:","code":"# Enable header/footer extraction (default = TRUE in updated code) result <- mistral_ocr(   \"document.pdf\",   extract_header = TRUE,  # Extracts running headers (journal name, page numbers, etc.)   extract_footer = TRUE   # Extracts footers (page numbers, copyright, etc.) )  # Headers and footers are now separated from main content # This was the main reason for switching to Tensorlake originally"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"table-formatting","dir":"","previous_headings":"2. Mistral OCR 3","what":"Table Formatting","title":"ohseer Usage Examples","text":"","code":"# Get tables in HTML format result <- mistral_ocr(\"document.pdf\", table_format = \"html\")  # Get tables in Markdown format (default) result <- mistral_ocr(\"document.pdf\", table_format = \"markdown\")"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"cost-optimization","dir":"","previous_headings":"2. Mistral OCR 3","what":"Cost Optimization","title":"ohseer Usage Examples","text":"","code":"# Use batch API for 50% discount ($0.001/page instead of $0.002/page) # (Batch API usage depends on your API client setup)  # With annotations (structured output): $0.003/page result <- mistral_ocr(   \"document.pdf\",   document_annotation_format = list(type = \"json_schema\", json_schema = schema) )"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"basic-usage-2","dir":"","previous_headings":"3. Tensorlake","what":"Basic Usage","title":"ohseer Usage Examples","text":"","code":"library(ohseer)  # Set API key Sys.setenv(TENSORLAKE_API_KEY = \"your-api-key\")  # Process document result <- tensorlake_ocr(\"document.pdf\")  # Extract pages pages <- tensorlake_extract_pages(result)"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"process-specific-pages","dir":"","previous_headings":"3. Tensorlake","what":"Process Specific Pages","title":"ohseer Usage Examples","text":"","code":"# Process only first 5 pages (saves cost and time) result <- tensorlake_ocr(\"document.pdf\", pages = 1:5)  # Process specific pages result <- tensorlake_ocr(\"document.pdf\", pages = c(1, 3, 5))  # Extract specific pages pages <- tensorlake_extract_pages(result, pages = c(1, 2))"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"exclude-fragment-types","dir":"","previous_headings":"3. Tensorlake","what":"Exclude Fragment Types","title":"ohseer Usage Examples","text":"","code":"# By default, all fragment types are included (including headers/footers) pages <- tensorlake_extract_pages(result)  # Exclude certain types if needed pages <- tensorlake_extract_pages(   result,   exclude_types = c(\"page_number\", \"page_footer\") )"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"use-claude-opus-45-when","dir":"","previous_headings":"Comparison: When to Use Each Provider","what":"Use Claude Opus 4.5 When:","title":"ohseer Usage Examples","text":"Maximum accuracy critical Processing legal, medical, high-value documents Document complex handwriting Tables intricate nested Multi-page context important Budget allows ~$0.05-0.09/page","code":""},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"use-mistral-ocr-3-when","dir":"","previous_headings":"Comparison: When to Use Each Provider","what":"Use Mistral OCR 3 When:","title":"ohseer Usage Examples","text":"Processing millions pages (cost-sensitive) Documents relatively clean/standard Need structured output lowest cost Batch processing available Budget: $0.001-0.003/page","code":""},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"use-tensorlake-when","dir":"","previous_headings":"Comparison: When to Use Each Provider","what":"Use Tensorlake When:","title":"ohseer Usage Examples","text":"Need balance accuracy cost Processing academic/scientific papers Good fragment-type classification needed Async processing large files Budget: $0.01/page","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"complete-example-processing-a-scientific-paper","dir":"","previous_headings":"","what":"Complete Example: Processing a Scientific Paper","title":"ohseer Usage Examples","text":"","code":"library(ohseer) library(ecoextract)  # 1. Choose provider based on needs # Option A: Maximum accuracy (Claude Opus 4.5) result <- claude_ocr(\"paper.pdf\") pages <- claude_extract_pages(result)  # Option B: Cost-optimized (Mistral OCR 3) schema <- list(...)  # Tensorlake-compatible schema result <- mistral_ocr(   \"paper.pdf\",   document_annotation_format = list(type = \"json_schema\", json_schema = schema),   extract_header = TRUE,   extract_footer = TRUE ) pages <- mistral_extract_pages(result)  # Option C: Balanced (Tensorlake) result <- tensorlake_ocr(\"paper.pdf\") pages <- tensorlake_extract_pages(result)  # 2. All providers return same structure str(pages) # List of 10 (pages) #  $ :List of 6 #   ..$ page_number   : int 1 #   ..$ page_header   : chr [1:2] \"Journal Name\" \"Volume 10, 2026\" #   ..$ section_header: chr \"Introduction\" #   ..$ text          : chr \"The study examines...\" #   ..$ tables        :List of 1 #   .. ..$ :List of 4 #   .. .. ..$ content : chr \"Species\\tCount\\n...\" #   .. .. ..$ markdown: chr \"| Species | Count |\\n...\" #   .. .. ..$ html    : chr \"<table><tr><th>Species...\" #   .. .. ..$ summary : chr \"Table 1: Species abundance\" #   ..$ other         :List of 1 #   .. ..$ :List of 2 #   .. .. ..$ type   : chr \"figure_caption\" #   .. .. ..$ content: chr \"Figure 1. Study site map\"  # 3. Convert to JSON for ecoextract json_content <- jsonlite::toJSON(pages, auto_unbox = TRUE, pretty = TRUE)  # 4. Use with ecoextract db_conn <- DBI::dbConnect(RSQLite::SQLite(), \"my_database.db\") ecoextract::create_database_schema(db_conn)  # Store document doc_id <- ecoextract::add_document(   db_conn = db_conn,   document_name = \"paper.pdf\",   document_content = json_content )  # Extract metadata ecoextract::extract_metadata(doc_id, db_conn)  # Extract records ecoextract::extract_records(doc_id, db_conn)"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"headersfooters-not-extracted-mistral","dir":"","previous_headings":"Troubleshooting","what":"Headers/Footers Not Extracted (Mistral)","title":"ohseer Usage Examples","text":"Make sure ’re using OCR 3 enabled extraction:","code":"result <- mistral_ocr(   \"document.pdf\",   model = \"mistral-ocr-2512\",  # OCR 3   extract_header = TRUE,   extract_footer = TRUE )"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"structured-output-not-working-mistral","dir":"","previous_headings":"Troubleshooting","what":"Structured Output Not Working (Mistral)","title":"ohseer Usage Examples","text":"Ensure ’re using document_annotation_format parameter:","code":"result <- mistral_ocr(   \"document.pdf\",   document_annotation_format = list(     type = \"json_schema\",     json_schema = your_schema   ) )"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"claude-response-not-parsed","dir":"","previous_headings":"Troubleshooting","what":"Claude Response Not Parsed","title":"ohseer Usage Examples","text":"Check structured_output field exists:","code":"result <- claude_ocr(\"document.pdf\") if (is.null(result$structured_output)) {   # Claude may have returned non-JSON text   print(result$raw_text) }"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"cost-higher-than-expected-claude","dir":"","previous_headings":"Troubleshooting","what":"Cost Higher Than Expected (Claude)","title":"ohseer Usage Examples","text":"Monitor token usage optimize:","code":"# Check usage result$usage  # Reduce max_tokens if needed result <- claude_ocr(\"document.pdf\", max_tokens = 8000)  # Use Sonnet instead of Opus result <- claude_ocr(\"document.pdf\", model = \"claude-sonnet-4.5-20250929\")"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"api-keys-setup","dir":"","previous_headings":"","what":"API Keys Setup","title":"ohseer Usage Examples","text":"Set environment variables .Renviron file: set R session:","code":"# Claude Opus 4.5 ANTHROPIC_API_KEY=sk-ant-your-key-here  # Mistral OCR 3 MISTRAL_API_KEY=your-mistral-key-here  # Tensorlake TENSORLAKE_API_KEY=your-tensorlake-key-here Sys.setenv(ANTHROPIC_API_KEY = \"your-key\") Sys.setenv(MISTRAL_API_KEY = \"your-key\") Sys.setenv(TENSORLAKE_API_KEY = \"your-key\")"},{"path":"https://n8layman.github.io/ohseer/USAGE_EXAMPLES.html","id":"additional-resources","dir":"","previous_headings":"","what":"Additional Resources","title":"ohseer Usage Examples","text":"Cost Comparison - Detailed pricing analysis OCR Arena Leaderboard - Live rankings Claude Pricing Mistral OCR 3 Docs Tensorlake Pricing","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Claude OCR with Structured Outputs","text":"vignette explains Claude’s structured output feature works ohseer package. Claude Opus 4.6 Sonnet 4.5 support guaranteed JSON schema compliance constrained decoding inference.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"basic-usage","dir":"Articles","previous_headings":"Introduction","what":"Basic Usage","title":"Claude OCR with Structured Outputs","text":"","code":"library(ohseer)  # Process a document with Claude OCR using structured outputs result <- claude_ocr_process_file(   file_path = \"document.pdf\",   model = \"claude-opus-4-6\" )"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"how-structured-outputs-work","dir":"Articles","previous_headings":"","what":"How Structured Outputs Work","title":"Claude OCR with Structured Outputs","text":"Claude’s structured output uses output_config.format parameter JSON schema guarantee response matches specified structure.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"api-configuration","dir":"Articles","previous_headings":"How Structured Outputs Work","what":"API Configuration","title":"Claude OCR with Structured Outputs","text":"","code":"request_body <- list(   model = \"claude-opus-4-6\",   max_tokens = 16000,   messages = list(...),   output_config = list(     format = list(       type = \"json_schema\",       schema = your_schema     )   ) )"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"key-features","dir":"Articles","previous_headings":"How Structured Outputs Work","what":"Key Features","title":"Claude OCR with Structured Outputs","text":"Guaranteed Compliance: Response always match provided JSON schema Constrained Decoding: Uses constrained decoding inference (post-processing) Available Models: Claude Opus 4.6 Claude Sonnet 4.5 Parsing Errors: Eliminates JSON parsing failures malformed responses","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"default-schema-tensorlake-compatible-format","dir":"Articles","previous_headings":"","what":"Default Schema: Tensorlake-Compatible Format","title":"Claude OCR with Structured Outputs","text":"default, claude_ocr_process_file() uses Tensorlake-compatible schema consistency across providers.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"schema-structure","dir":"Articles","previous_headings":"Default Schema: Tensorlake-Compatible Format","what":"Schema Structure","title":"Claude OCR with Structured Outputs","text":"default schema defines pages fragment types:","code":"{   \"pages\": [     {       \"page_number\": 1,       \"page_fragments\": [         {           \"fragment_type\": \"page_header\",           \"content\": { \"content\": \"...\" },           \"reading_order\": 1         },         {           \"fragment_type\": \"section_header\",           \"content\": { \"content\": \"...\" },           \"reading_order\": 2         },         {           \"fragment_type\": \"text\",           \"content\": { \"content\": \"...\" },           \"reading_order\": 3         },         {           \"fragment_type\": \"table\",           \"content\": {             \"content\": \"plain text\",             \"html\": \"<table>...<\/table>\",             \"markdown\": \"| col1 | col2 |...\"           },           \"reading_order\": 4         }       ]     }   ] }"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"fragment-types","dir":"Articles","previous_headings":"Default Schema: Tensorlake-Compatible Format","what":"Fragment Types","title":"Claude OCR with Structured Outputs","text":"schema supports fragment types: page_header: Headers top pages (journal name, volume, etc.) page_number: Page numbers section_header: Section/chapter headings text: Regular paragraph text table: Tables content, html, markdown representations table_caption: Table captions/titles figure: Images figures figure_caption: Figure captions list: Lists footnote: Footnotes equation: Mathematical equations code: Code blocks : content type","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"using-the-default-schema","dir":"Articles","previous_headings":"","what":"Using the Default Schema","title":"Claude OCR with Structured Outputs","text":"default behavior provides structured, Tensorlake-compatible output:","code":"library(ohseer)  # Process with default Tensorlake schema result <- claude_ocr_process_file(\"paper.pdf\")  # Access structured pages pages <- result$pages  # First page page1 <- pages[[1]] page1$page_number  # 1  # Get all text fragments text_fragments <- Filter(function(f) f$fragment_type == \"text\", page1$page_fragments)  # Get all tables table_fragments <- Filter(function(f) f$fragment_type == \"table\", page1$page_fragments)  # Access table in markdown format if (length(table_fragments) > 0) {   table1_markdown <- table_fragments[[1]]$content$markdown   cat(table1_markdown) }"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"custom-schemas","dir":"Articles","previous_headings":"","what":"Custom Schemas","title":"Claude OCR with Structured Outputs","text":"can provide JSON schema custom output structures.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"example-simple-schema","dir":"Articles","previous_headings":"Custom Schemas","what":"Example: Simple Schema","title":"Claude OCR with Structured Outputs","text":"","code":"# Define a simple schema for extracting just titles and authors simple_schema <- list(   type = \"object\",   properties = list(     title = list(type = \"string\"),     authors = list(       type = \"array\",       items = list(type = \"string\")     ),     abstract = list(type = \"string\")   ),   required = c(\"title\", \"authors\", \"abstract\") )  # Use with custom prompt result <- claude_api_call(   prompt = \"Extract the title, authors, and abstract from this paper.\",   image_data = list(base64_image),   schema = simple_schema,   model = \"claude-opus-4-6\" )  # Access results cat(\"Title:\", result$content[[1]]$text$title, \"\\n\") cat(\"Authors:\", paste(result$content[[1]]$text$authors, collapse = \", \"), \"\\n\")"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"example-metadata-extraction","dir":"Articles","previous_headings":"Custom Schemas","what":"Example: Metadata Extraction","title":"Claude OCR with Structured Outputs","text":"","code":"# Schema for scientific paper metadata metadata_schema <- list(   type = \"object\",   properties = list(     title = list(type = \"string\"),     authors = list(       type = \"array\",       items = list(         type = \"object\",         properties = list(           name = list(type = \"string\"),           affiliation = list(type = \"string\")         )       )     ),     journal = list(type = \"string\"),     year = list(type = \"integer\"),     doi = list(type = \"string\"),     keywords = list(       type = \"array\",       items = list(type = \"string\")     )   ),   required = c(\"title\", \"authors\", \"journal\") )  # Process first 2 pages for metadata result <- claude_ocr_process_file(   \"paper.pdf\",   pages = c(1, 2),   schema = metadata_schema,   prompt = \"Extract bibliographic metadata from this scientific paper.\" )"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"page-selection","dir":"Articles","previous_headings":"Processing Options","what":"Page Selection","title":"Claude OCR with Structured Outputs","text":"Process specific pages :","code":"# Process first 3 pages result <- claude_ocr_process_file(   \"paper.pdf\",   pages = c(1, 2, 3),   model = \"claude-opus-4-6\" )"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"model-selection","dir":"Articles","previous_headings":"Processing Options","what":"Model Selection","title":"Claude OCR with Structured Outputs","text":"Choose available models:","code":"# Use Opus 4.6 (most capable, slower, more expensive) result_opus <- claude_ocr_process_file(\"paper.pdf\", model = \"claude-opus-4-6\")  # Use Sonnet 4.5 (fast, cost-effective) result_sonnet <- claude_ocr_process_file(\"paper.pdf\", model = \"claude-sonnet-4-5\")"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"image-quality","dir":"Articles","previous_headings":"Processing Options","what":"Image Quality","title":"Claude OCR with Structured Outputs","text":"Adjust image processing:","code":"result <- claude_ocr_process_file(   \"paper.pdf\",   dpi = 200,  # Higher DPI for better quality   model = \"claude-opus-4-6\" )"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"complete-example","dir":"Articles","previous_headings":"","what":"Complete Example","title":"Claude OCR with Structured Outputs","text":"’s complete workflow extracting structured data scientific paper:","code":"library(ohseer) library(jsonlite)  # 1. Process first 2 pages with Claude for metadata extraction metadata_result <- claude_ocr_process_file(   \"paper.pdf\",   pages = c(1, 2),   model = \"claude-sonnet-4-5\"  # Fast model for metadata )  # 2. Access structured data page1 <- metadata_result$pages[[1]]  # 3. Extract citation information page_headers <- Filter(function(f) f$fragment_type == \"page_header\", page1$page_fragments) section_headers <- Filter(function(f) f$fragment_type == \"section_header\", page1$page_fragments)  if (length(page_headers) > 0) {   cat(\"Journal:\", page_headers[[1]]$content$content, \"\\n\") }  if (length(section_headers) > 0) {   cat(\"Title:\", section_headers[[1]]$content$content, \"\\n\") }  # 4. Extract all tables all_tables <- list() for (page in metadata_result$pages) {   table_frags <- Filter(function(f) f$fragment_type == \"table\", page$page_fragments)   for (table in table_frags) {     all_tables[[length(all_tables) + 1]] <- list(       page = page$page_number,       markdown = table$content$markdown,       html = table$content$html     )   } }  cat(\"Found\", length(all_tables), \"tables\\n\")  # 5. Convert to JSON for further processing json_output <- toJSON(metadata_result$pages, auto_unbox = TRUE, pretty = TRUE)"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"reliability","dir":"Articles","previous_headings":"Benefits of Structured Outputs","what":"1. Reliability","title":"Claude OCR with Structured Outputs","text":"Guaranteed Format: parsing errors malformed JSON Type Safety: Schema ensures correct data types Required Fields: Can specify fields must present","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"consistency","dir":"Articles","previous_headings":"Benefits of Structured Outputs","what":"2. Consistency","title":"Claude OCR with Structured Outputs","text":"Tensorlake Compatible: Default schema matches Tensorlake format Predictable Structure: structure across documents Easy Integration: Works seamlessly existing pipelines","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"efficiency","dir":"Articles","previous_headings":"Benefits of Structured Outputs","what":"3. Efficiency","title":"Claude OCR with Structured Outputs","text":"Single Pass: Get structured data one API call Post-Processing: need additional parsing validation Direct Use: Output immediately usable","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"claude-vs-tensorlake","dir":"Articles","previous_headings":"Comparison with Other Providers","what":"Claude vs Tensorlake","title":"Claude OCR with Structured Outputs","text":"Claude: Uses structured outputs (guaranteed JSON schema) Tensorlake: Returns structured fragments natively Compatible: can use page fragment structure","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"claude-vs-mistral","dir":"Articles","previous_headings":"Comparison with Other Providers","what":"Claude vs Mistral","title":"Claude OCR with Structured Outputs","text":"Claude: Structured outputs JSON schema Mistral: Native format (structured output transformation) Different Use Cases: Claude guaranteed structure, Mistral flexible native format","code":""},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"tips-and-best-practices","dir":"Articles","previous_headings":"","what":"Tips and Best Practices","title":"Claude OCR with Structured Outputs","text":"Model Selection: Use Sonnet 4.5 tasks (fast cost-effective): Page Selection: Process needed pages save costs: Schema Design: Keep schemas simple focused: Error Handling: Always validate response: Cost Optimization: Balance quality cost: Use Sonnet 4.5 routine processing Use Opus 4.6 complex documents highest accuracy needed Process minimum pages necessary","code":"result <- claude_ocr_process_file(\"doc.pdf\", model = \"claude-sonnet-4-5\") # Metadata usually on first 1-2 pages result <- claude_ocr_process_file(\"doc.pdf\", pages = c(1, 2)) # Good: Simple, focused schema simple <- list(type = \"object\", properties = list(title = list(type = \"string\")))  # Avoid: Overly complex nested structures if (is.null(result$pages) || length(result$pages) == 0) {   stop(\"No pages returned from Claude OCR\") }"},{"path":"https://n8layman.github.io/ohseer/articles/claude-structured-output.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Claude OCR with Structured Outputs","text":"Claude Setup Guide Tensorlake Output Structure Mistral Output Structure Package README Claude API documentation: https://docs.anthropic.com","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Understanding Mistral OCR Output Structure","text":"vignette explains native structure objects returned Mistral’s OCR functions. ohseer package returns Mistral’s native format without post-processing, allowing applications handle transformations needed.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"basic-usage","dir":"Articles","previous_headings":"Introduction","what":"Basic Usage","title":"Understanding Mistral OCR Output Structure","text":"","code":"library(ohseer)  # Parse a document with Mistral OCR result <- mistral_ocr(\"document.pdf\",                      extract_header = TRUE,                      extract_footer = TRUE)  # Extract pages (returns native Mistral format) pages <- mistral_extract_pages(result)"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"output-structure","dir":"Articles","previous_headings":"","what":"Output Structure","title":"Understanding Mistral OCR Output Structure","text":"mistral_ocr() function returns list Mistral’s complete response structure.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"top-level-fields","dir":"Articles","previous_headings":"Output Structure","what":"Top-Level Fields","title":"Understanding Mistral OCR Output Structure","text":"Key top-level fields include: id: Unique job identifier object: Object type (typically “document_ocr”) model: Model used (e.g., “mistral-ocr-2512”) usage: Token usage statistics pages: List page objects (detailed ) created: Timestamp creation","code":"str(result, max.level = 1)"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"page-structure","dir":"Articles","previous_headings":"","what":"Page Structure","title":"Understanding Mistral OCR Output Structure","text":"element result$pages represents one page contains:","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"page-fields","dir":"Articles","previous_headings":"Page Structure","what":"Page Fields","title":"Understanding Mistral OCR Output Structure","text":"page object 8 fields: index: 0-based page number (first page = 0) markdown: Full page content markdown format images: Array extracted images (base64 URLs) tables: Array table objects (detailed ) hyperlinks: Array hyperlinks detected page header: Page header text (extract_header = TRUE) footer: Page footer text (extract_footer = TRUE) dimensions: Page dimensions object","code":"page1 <- result$pages[[1]] str(page1, max.level = 1)"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"example-page-structure","dir":"Articles","previous_headings":"Page Structure","what":"Example Page Structure","title":"Understanding Mistral OCR Output Structure","text":"","code":"{   \"index\": 0,   \"markdown\": \"# Page Title\\n\\nPage content here...\",   \"images\": [],   \"tables\": [...],   \"hyperlinks\": [],   \"header\": \"JOURNAL NAME - Volume 1\",   \"footer\": \"Page 1\",   \"dimensions\": {     \"dpi\": 200,     \"height\": 1942,     \"width\": 2828   } }"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"table-structure","dir":"Articles","previous_headings":"","what":"Table Structure","title":"Understanding Mistral OCR Output Structure","text":"Tables extracted stored tables array page.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"table-fields","dir":"Articles","previous_headings":"Table Structure","what":"Table Fields","title":"Understanding Mistral OCR Output Structure","text":"table 3 fields: id: Unique table identifier (e.g., “tbl-0.md”) content: Markdown-formatted table content format: Format type (typically “markdown”)","code":"table1 <- page1$tables[[1]] str(table1)"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"example-table","dir":"Articles","previous_headings":"Table Structure","what":"Example Table","title":"Understanding Mistral OCR Output Structure","text":"","code":"{   \"id\": \"tbl-0.md\",   \"content\": \"| Species | Location | Age (years) |\\n| --- | --- | --- |\\n| E. camaldu... \",   \"format\": \"markdown\" }"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"table-references-in-markdown","dir":"Articles","previous_headings":"Table Structure","what":"Table References in Markdown","title":"Understanding Mistral OCR Output Structure","text":"Tables referenced page markdown using markdown link syntax: actual table content tables array, embedded markdown.","code":"See Table 1 below:  [tbl-0.md](tbl-0.md)"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"headers-and-footers","dir":"Articles","previous_headings":"","what":"Headers and Footers","title":"Understanding Mistral OCR Output Structure","text":"enable header/footer extraction, Mistral separates main content.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"extraction-options","dir":"Articles","previous_headings":"Headers and Footers","what":"Extraction Options","title":"Understanding Mistral OCR Output Structure","text":"","code":"result <- mistral_ocr(\"document.pdf\",                      extract_header = TRUE,  # Extract running headers                      extract_footer = TRUE)  # Extract page numbers/footers"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"headerfooter-format","dir":"Articles","previous_headings":"Headers and Footers","what":"Header/Footer Format","title":"Understanding Mistral OCR Output Structure","text":"Headers footers can : String: \"CHAPTER FIVE\\n64 RETENTION TREES HOLLOWS\" Empty object: {} (header/footer detected) NULL: extraction disabled","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"benefits-of-extraction","dir":"Articles","previous_headings":"Headers and Footers","what":"Benefits of Extraction","title":"Understanding Mistral OCR Output Structure","text":"Extracting headers/footers separately: Removes repetitive content page markdown Preserves page numbers running headers reference Keeps body text cleaner downstream processing","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"dimensions-object","dir":"Articles","previous_headings":"","what":"Dimensions Object","title":"Understanding Mistral OCR Output Structure","text":"page includes dimension information rendering calculations.","code":"page1$dimensions"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"dimension-fields","dir":"Articles","previous_headings":"Dimensions Object","what":"Dimension Fields","title":"Understanding Mistral OCR Output Structure","text":"dpi: Dots per inch (resolution) height: Page height pixels width: Page width pixels","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"get-specific-pages","dir":"Articles","previous_headings":"Extracting Information","what":"Get Specific Pages","title":"Understanding Mistral OCR Output Structure","text":"Use mistral_extract_pages() filter specific pages:","code":"# Extract first 3 pages only first_three <- mistral_extract_pages(result, pages = c(1, 2, 3))  # Note: page numbers in the pages argument are 1-based # But the 'index' field in each page is 0-based"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"extract-all-text","dir":"Articles","previous_headings":"Extracting Information","what":"Extract All Text","title":"Understanding Mistral OCR Output Structure","text":"Combine markdown pages:","code":"all_text <- sapply(result$pages, function(p) p$markdown) full_document <- paste(all_text, collapse = \"\\n\\n\")"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"extract-all-tables","dir":"Articles","previous_headings":"Extracting Information","what":"Extract All Tables","title":"Understanding Mistral OCR Output Structure","text":"Collect tables document:","code":"all_tables <- list() for (i in seq_along(result$pages)) {   page <- result$pages[[i]]   if (length(page$tables) > 0) {     for (j in seq_along(page$tables)) {       all_tables[[length(all_tables) + 1]] <- list(         page_number = i,  # 1-based for human readability         page_index = page$index,  # 0-based as in original         table_id = page$tables[[j]]$id,         content = page$tables[[j]]$content       )     }   } }  # View table summary do.call(rbind, lapply(all_tables, function(t) {   data.frame(     page = t$page_number,     table_id = t$table_id,     chars = nchar(t$content)   ) }))"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"parse-table-markdown","dir":"Articles","previous_headings":"Extracting Information","what":"Parse Table Markdown","title":"Understanding Mistral OCR Output Structure","text":"Convert markdown tables data frames:","code":"library(knitr)  # Get first table table1 <- result$pages[[1]]$tables[[1]]  # Parse markdown to data frame (requires knitr) # Note: This is a simple approach; more robust parsing may be needed lines <- strsplit(table1$content, \"\\n\")[[1]] # Remove separator line (usually second line with ---) data_lines <- lines[!grepl(\"^\\\\|?[-\\\\s]+\\\\|[-\\\\s]+\", lines)]  # You can also send the markdown to an LLM for structured extraction"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"extract-hyperlinks","dir":"Articles","previous_headings":"Extracting Information","what":"Extract Hyperlinks","title":"Understanding Mistral OCR Output Structure","text":"Access hyperlinks found pages:","code":"for (i in seq_along(result$pages)) {   page <- result$pages[[i]]   if (length(page$hyperlinks) > 0) {     cat(\"Page\", i, \"hyperlinks:\\n\")     print(page$hyperlinks)   } }"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"complete-example","dir":"Articles","previous_headings":"","what":"Complete Example","title":"Understanding Mistral OCR Output Structure","text":"’s complete workflow processing scientific paper:","code":"library(ohseer) library(jsonlite)  # 1. Parse the document with header/footer extraction result <- mistral_ocr(\"paper.pdf\",                      extract_header = TRUE,                      extract_footer = TRUE,                      table_format = \"markdown\")  # 2. Extract all pages pages <- mistral_extract_pages(result)  # 3. Examine first page structure page1 <- pages[[1]] cat(\"Page\", page1$index + 1, \"\\n\")  # +1 for 1-based display cat(\"Header:\", page1$header, \"\\n\") cat(\"Footer:\", if(is.null(page1$footer) || length(page1$footer) == 0) \"None\" else page1$footer, \"\\n\") cat(\"Tables:\", length(page1$tables), \"\\n\") cat(\"Images:\", length(page1$images), \"\\n\")  # 4. Extract all tables with page information all_tables <- list() for (page in pages) {   for (table in page$tables) {     all_tables[[length(all_tables) + 1]] <- list(       page = page$index + 1,  # Convert to 1-based       id = table$id,       markdown = table$content     )   } }  cat(\"Total tables found:\", length(all_tables), \"\\n\")  # 5. Convert to JSON for downstream processing json_output <- toJSON(pages, auto_unbox = TRUE, pretty = TRUE)  # 6. Process with your application # Applications can implement their own transformations based on needs"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"index-numbering","dir":"Articles","previous_headings":"Key Differences from Other Providers","what":"Index Numbering","title":"Understanding Mistral OCR Output Structure","text":"Mistral: Uses 0-based indexing index field (first page = 0) Tensorlake: Uses 1-based page_number (first page = 1) Always remember filtering displaying page numbers.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"table-handling","dir":"Articles","previous_headings":"Key Differences from Other Providers","what":"Table Handling","title":"Understanding Mistral OCR Output Structure","text":"Mistral: Tables referenced [tbl-0.md](tbl-0.md) markdown, full content tables array Tensorlake: Tables embedded page fragments fragment type","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"no-post-processing","dir":"Articles","previous_headings":"Key Differences from Other Providers","what":"No Post-Processing","title":"Understanding Mistral OCR Output Structure","text":"ohseer package returns Mistral’s native format without transformation. means: Applications control data transformations imposed structure may fit use cases Direct access fields Mistral provides Simpler, maintainable package code","code":""},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"tips-and-best-practices","dir":"Articles","previous_headings":"","what":"Tips and Best Practices","title":"Understanding Mistral OCR Output Structure","text":"Page Numbering: Always aware 0-based index vs 1-based page references: Header/Footer Extraction: Enable cleaner body text: Table Format: Request markdown format easier parsing: Image Handling: Use include_image_base64 = TRUE get images: JSON Export: LLM processing, convert JSON: Validate Results: Check OCR completed successfully:","code":"# To get \"page 1\" (human numbering): page1 <- pages[[1]]  # R uses 1-based indexing # But page1$index will be 0 result <- mistral_ocr(\"doc.pdf\", extract_header = TRUE, extract_footer = TRUE) result <- mistral_ocr(\"doc.pdf\", table_format = \"markdown\") result <- mistral_ocr(\"doc.pdf\", include_image_base64 = TRUE) # Access with: pages[[1]]$images library(jsonlite) json_str <- toJSON(pages, auto_unbox = TRUE, pretty = TRUE) # Send to Claude, GPT, etc. for structured extraction if (is.null(result$pages) || length(result$pages) == 0) {   stop(\"OCR returned no pages\") }"},{"path":"https://n8layman.github.io/ohseer/articles/mistral-output-structure.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Understanding Mistral OCR Output Structure","text":"Mistral Setup Guide Tensorlake Output Structure Package README Mistral AI API documentation: https://docs.mistral.ai","code":""},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Understanding Tensorlake Output Structure","text":"vignette explains structure objects returned Tensorlake’s OCR functions shows extract different types information results.","code":""},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"basic-usage","dir":"Articles","previous_headings":"Introduction","what":"Basic Usage","title":"Understanding Tensorlake Output Structure","text":"","code":"library(ohseer)  # Parse a document with Tensorlake result <- tensorlake_ocr(\"document.pdf\")"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"output-structure","dir":"Articles","previous_headings":"","what":"Output Structure","title":"Understanding Tensorlake Output Structure","text":"tensorlake_ocr() function returns list following top-level fields:","code":""},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"top-level-fields","dir":"Articles","previous_headings":"Output Structure","what":"Top-Level Fields","title":"Understanding Tensorlake Output Structure","text":"parse_id: Unique identifier parse job status: Parse job status (e.g., “successful”, “failed”) total_pages: Total number pages document parsed_pages_count: Number pages successfully parsed pages: List parsed page data (detailed ) chunks: List text chunks extracted document page_classes: Classification page types (applicable) created_at: Timestamp parse job created (ISO 8601 format) finished_at: Timestamp parse job completed (ISO 8601 format) usage: API usage statistics (tokens, pages, etc.)","code":"str(result, max.level = 1)"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"page-structure","dir":"Articles","previous_headings":"","what":"Page Structure","title":"Understanding Tensorlake Output Structure","text":"element result$pages represents one page contains:","code":""},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"page-fields","dir":"Articles","previous_headings":"Page Structure","what":"Page Fields","title":"Understanding Tensorlake Output Structure","text":"page_number: Page number (integer) page_fragments: List content fragments found page dimensions: Page dimensions (width, height) page_dimensions: Alternative dimension measurements classification_reason: Reason page classification (applicable)","code":"page1 <- result$pages[[1]] str(page1, max.level = 1)"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"page-fragments","dir":"Articles","previous_headings":"Page Structure","what":"Page Fragments","title":"Understanding Tensorlake Output Structure","text":"page contains multiple fragments representing different content types:","code":"fragment <- page1$page_fragments[[1]] str(fragment, max.level = 2)"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"fragment-fields","dir":"Articles","previous_headings":"Page Structure > Page Fragments","what":"Fragment Fields","title":"Understanding Tensorlake Output Structure","text":"fragment_type: Type content (see types ) content$content: text content content$html: HTML representation (tables) reading_order: Position reading sequence (integer) x1, y1: Top-left corner x2, y2: Bottom-right corner","code":""},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"fragment-types","dir":"Articles","previous_headings":"Page Structure > Page Fragments","what":"Fragment Types","title":"Understanding Tensorlake Output Structure","text":"Tensorlake identifies several content types:","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"extract-structured-page-data","dir":"Articles","previous_headings":"Extracting Information","what":"Extract Structured Page Data","title":"Understanding Tensorlake Output Structure","text":"Use tensorlake_extract_pages() get organized content fragment type:","code":"# Extract first 2 pages with structured data pages <- tensorlake_extract_pages(result, pages = c(1, 2))  # Access first page page1 <- pages[[1]]  # Page structure: page1$page_number      # Page number page1$page_header      # Character vector of page headers (e.g., journal citation) page1$section_header   # Character vector of section headers (e.g., article title) page1$text            # String with all text content (markdown format) page1$tables          # List of tables with content, markdown, html formats page1$other           # Other fragment types  # Example: Get citation info from first page citation <- page1$page_header title <- page1$section_header  # Example: Access table data if (length(page1$tables) > 0) {   table1 <- page1$tables[[1]]   cat(table1$markdown)  # Markdown format   cat(table1$html)      # HTML format   cat(table1$content)   # Plain text }  # Convert to JSON for LLM processing library(jsonlite) json_for_llm <- toJSON(pages, auto_unbox = TRUE, pretty = TRUE)"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"extract-metadata","dir":"Articles","previous_headings":"Extracting Information","what":"Extract Metadata","title":"Understanding Tensorlake Output Structure","text":"Access document metadata directly result:","code":"# View processing statistics cat(\"Parse ID:\", result$parse_id, \"\\n\") cat(\"Pages processed:\", result$parsed_pages_count, \"of\", result$total_pages, \"\\n\") cat(\"Status:\", result$status, \"\\n\")  # View usage statistics str(result$usage)"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"filter-by-fragment-type","dir":"Articles","previous_headings":"Working with Fragments","what":"Filter by Fragment Type","title":"Understanding Tensorlake Output Structure","text":"Find headers document:","code":"# Get all section headers headers <- list() for (page in result$pages) {   for (frag in page$page_fragments) {     if (frag$fragment_type == \"section_header\") {       headers[[length(headers) + 1]] <- list(         page = page$page_number,         text = frag$content$content,         order = frag$reading_order       )     }   } }  # View headers do.call(rbind, lapply(headers, as.data.frame))"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"extract-text-in-reading-order","dir":"Articles","previous_headings":"Working with Fragments","what":"Extract Text in Reading Order","title":"Understanding Tensorlake Output Structure","text":"Get text fragments order read:","code":"# For a specific page page_num <- 1 page <- result$pages[[page_num]]  # Sort fragments by reading order sorted_fragments <- page$page_fragments[order(sapply(page$page_fragments, function(f) f$reading_order))]  # Extract text in order ordered_text <- sapply(sorted_fragments, function(frag) {   frag$content$content %||% \"\" })  cat(paste(ordered_text, collapse = \"\\n\"))"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"complete-example","dir":"Articles","previous_headings":"","what":"Complete Example","title":"Understanding Tensorlake Output Structure","text":"’s complete workflow processing academic paper:","code":"library(ohseer) library(jsonlite)  # 1. Parse the document result <- tensorlake_ocr(\"paper.pdf\")  # 2. Check status cat(\"Status:\", result$status, \"\\n\") cat(\"Processed\", result$parsed_pages_count, \"pages\\n\")  # 3. Extract structured data from first 2 pages (for citation metadata) pages <- tensorlake_extract_pages(result, pages = c(1, 2))  # 4. Access citation information page1 <- pages[[1]] cat(\"Journal:\", page1$page_header, \"\\n\") cat(\"Title:\", page1$section_header, \"\\n\")  # 5. Convert to JSON for LLM processing json_data <- toJSON(pages, auto_unbox = TRUE, pretty = TRUE)  # Send json_data to Claude or another LLM for metadata extraction  # 6. Access tables if needed for (page in pages) {   if (length(page$tables) > 0) {     cat(\"Found\", length(page$tables), \"tables on page\", page$page_number, \"\\n\")   } }"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"tips-and-best-practices","dir":"Articles","previous_headings":"","what":"Tips and Best Practices","title":"Understanding Tensorlake Output Structure","text":"Fragment Types: Different documents may different fragment types. Always check ’s available: Reading Order: Use reading_order maintain document flow extracting text. Bounding Boxes: Use bbox coordinates need know content appears page. Page Selection: citation extraction, processing just first 1-2 pages usually sufficient faster. Error Handling: Always check result$status ensure parsing succeeded:","code":"all_types <- unique(unlist(lapply(result$pages, function(p) {   sapply(p$page_fragments, function(f) f$fragment_type) }))) table(all_types) if (result$status != \"successful\") {   stop(\"Parsing failed or is incomplete\") }"},{"path":"https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Understanding Tensorlake Output Structure","text":"Tensorlake Setup Guide Package README Tensorlake API documentation: https://docs.tensorlake.ai","code":""},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with ohseer","text":"ohseer package provides unified interface multiple OCR (Optical Character Recognition) APIs single function: ohseer_ocr(). means can switch different OCR providers without changing code. Supported providers: Claude Opus 4.6/Sonnet 4.5: #1 OCR Arena, structured outputs JSON schemas Tensorlake: Highest accuracy (91.7%), best tables forms Mistral OCR 3: Native markdown output, cost-effective AWS Textract: Reliable option structured data extraction","code":""},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with ohseer","text":"","code":"# Using pak (recommended) pak::pak(\"n8layman/ohseer\")  # Using devtools devtools::install_github(\"n8layman/ohseer\")"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"authentication","dir":"Articles","previous_headings":"","what":"Authentication","title":"Getting Started with ohseer","text":"Set API keys environment variables: Option 2: Create .env file (recommended):","code":"# Option 1: Set for current session Sys.setenv(   ANTHROPIC_API_KEY = \"your-claude-key\",   TENSORLAKE_API_KEY = \"your-tensorlake-key\",   MISTRAL_API_KEY = \"your-mistral-key\" ) # .env ANTHROPIC_API_KEY=your-claude-key TENSORLAKE_API_KEY=your-tensorlake-key MISTRAL_API_KEY=your-mistral-key"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"getting-api-keys","dir":"Articles","previous_headings":"Authentication","what":"Getting API Keys","title":"Getting Started with ohseer","text":"Claude: Visit console.anthropic.com → API Keys Tensorlake: Visit cloud.tensorlake.ai → Dashboard → API Key Mistral: Visit mistral.ai → Try API → API keys AWS Textract: Visit aws.amazon.com → IAM → Create access key","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"process-a-document","dir":"Articles","previous_headings":"Basic Usage","what":"Process a Document","title":"Getting Started with ohseer","text":"","code":"library(ohseer)  # Process with default provider (Tensorlake) result <- ohseer_ocr(\"document.pdf\")  # Access the extracted pages pages <- result$pages  # Check which provider was used result$provider"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"choose-a-provider","dir":"Articles","previous_headings":"Basic Usage","what":"Choose a Provider","title":"Getting Started with ohseer","text":"","code":"# Use Claude for highest accuracy result <- ohseer_ocr(\"document.pdf\", provider = \"claude\")  # Use Mistral for cost-effectiveness result <- ohseer_ocr(\"document.pdf\", provider = \"mistral\")  # Use Tensorlake for best table extraction result <- ohseer_ocr(\"document.pdf\", provider = \"tensorlake\")"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"select-specific-pages","dir":"Articles","previous_headings":"Basic Usage","what":"Select Specific Pages","title":"Getting Started with ohseer","text":"","code":"# Process only first 2 pages result <- ohseer_ocr(\"document.pdf\", pages = c(1, 2))  # Process specific pages result <- ohseer_ocr(\"document.pdf\", pages = c(1, 5, 10))"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"provider-fallback","dir":"Articles","previous_headings":"","what":"Provider Fallback","title":"Getting Started with ohseer","text":"Automatically try multiple providers one succeeds: Note: providers API keys set tried. Providers without keys automatically skipped warning.","code":"# Try providers in order: Tensorlake → Mistral → Claude result <- ohseer_ocr(   \"document.pdf\",   provider = c(\"tensorlake\", \"mistral\", \"claude\") )  # Check which provider succeeded message(\"Used provider: \", result$provider)  # Check error log if any providers failed if (!is.na(result$error_log)) {   errors <- jsonlite::fromJSON(result$error_log)   print(errors) }"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"provider-specific-options","dir":"Articles","previous_headings":"","what":"Provider-Specific Options","title":"Getting Started with ohseer","text":"provider supports custom options via ...:","code":""},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"mistral-options","dir":"Articles","previous_headings":"Provider-Specific Options","what":"Mistral Options","title":"Getting Started with ohseer","text":"","code":"result <- ohseer_ocr(   \"document.pdf\",   provider = \"mistral\",   extract_header = TRUE,      # Extract headers separately   extract_footer = TRUE,      # Extract footers separately   table_format = \"markdown\"   # Table output format )"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"claude-options","dir":"Articles","previous_headings":"Provider-Specific Options","what":"Claude Options","title":"Getting Started with ohseer","text":"","code":"result <- ohseer_ocr(   \"document.pdf\",   provider = \"claude\",   model = \"claude-sonnet-4-5\",  # Use Sonnet instead of Opus   max_tokens = 16000,           # Maximum tokens   schema = my_custom_schema     # Custom JSON schema )"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"tensorlake-options","dir":"Articles","previous_headings":"Provider-Specific Options","what":"Tensorlake Options","title":"Getting Started with ohseer","text":"","code":"result <- ohseer_ocr(   \"document.pdf\",   provider = \"tensorlake\",   model = \"high-quality-v1\",    # Model selection   timeout = 120                 # Timeout in seconds )"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"result-structure","dir":"Articles","previous_headings":"Understanding Results","what":"Result Structure","title":"Getting Started with ohseer","text":"","code":"result <- ohseer_ocr(\"document.pdf\")  # Structure: result$provider   # Character: which provider was used result$pages      # List: extracted page data result$raw        # List: raw API response result$error_log  # Character (JSON): errors from failed providers"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"accessing-pages","dir":"Articles","previous_headings":"Understanding Results","what":"Accessing Pages","title":"Getting Started with ohseer","text":"Different providers return pages different formats: detailed information provider’s output format, see: Tensorlake Output Structure Mistral Output Structure Claude Structured Output","code":"# Tensorlake format result <- ohseer_ocr(\"doc.pdf\", provider = \"tensorlake\") page1 <- result$pages[[1]] page1$page_number      # Integer (1-based) page1$page_fragments   # List of content fragments  # Mistral format result <- ohseer_ocr(\"doc.pdf\", provider = \"mistral\") page1 <- result$pages[[1]] page1$index      # Integer (0-based) page1$markdown   # Full page content as markdown page1$tables     # Array of table objects  # Claude format (Tensorlake-compatible by default) result <- ohseer_ocr(\"doc.pdf\", provider = \"claude\") page1 <- result$pages[[1]] page1$page_number      # Integer (1-based) page1$page_fragments   # List of content fragments"},{"path":[]},{"path":[]},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"strategy-1-quality-first-with-fallback","dir":"Articles","previous_headings":"Common Patterns","what":"Strategy 1: Quality First with Fallback","title":"Getting Started with ohseer","text":"","code":"# Try highest quality first, fall back to cost-effective result <- ohseer_ocr(   \"document.pdf\",   provider = c(\"tensorlake\", \"mistral\") )"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"strategy-2-cost-optimized-with-fallback","dir":"Articles","previous_headings":"Common Patterns","what":"Strategy 2: Cost-Optimized with Fallback","title":"Getting Started with ohseer","text":"","code":"# Try lowest cost first, fall back to higher quality result <- ohseer_ocr(   \"document.pdf\",   provider = c(\"mistral\", \"tensorlake\", \"claude\") )"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"strategy-3-process-multiple-documents","dir":"Articles","previous_headings":"Common Patterns","what":"Strategy 3: Process Multiple Documents","title":"Getting Started with ohseer","text":"","code":"files <- c(\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\")  results <- lapply(files, function(file) {   tryCatch(     ohseer_ocr(file, provider = \"mistral\"),     error = function(e) {       warning(\"Failed to process \", file, \": \", e$message)       NULL     }   ) })  # Filter out failures successful_results <- Filter(Negate(is.null), results)"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"tips","dir":"Articles","previous_headings":"","what":"Tips","title":"Getting Started with ohseer","text":"Start simple: Use default provider settings, customize needed Process fewer pages: Reduce costs processing pages need Use provider fallback: Ensure reliability automatic failover Check provider used: Verify provider succeeded Store API keys securely: Use .env file add .gitignore","code":"result <- ohseer_ocr(\"document.pdf\") result <- ohseer_ocr(\"paper.pdf\", pages = c(1, 2)) result <- ohseer_ocr(\"doc.pdf\", provider = c(\"tensorlake\", \"mistral\")) message(\"Provider: \", result$provider)"},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"advanced-topics","dir":"Articles","previous_headings":"","what":"Advanced Topics","title":"Getting Started with ohseer","text":"advanced usage, see: Tensorlake Output Structure - Working fragment types Mistral Output Structure - Markdown table formats Claude Structured Output - Custom JSON schemas Function Reference - Complete API documentation","code":""},{"path":"https://n8layman.github.io/ohseer/articles/unified-interface.html","id":"provider-specific-functions","dir":"Articles","previous_headings":"","what":"Provider-Specific Functions","title":"Getting Started with ohseer","text":"ohseer_ocr() recommended, provider-specific functions still available advanced use: tensorlake_ocr() + tensorlake_extract_pages() mistral_ocr() + mistral_extract_pages() claude_ocr() + claude_extract_pages() textract_ocr() + textract_extract_metadata() See Function Reference details.","code":""},{"path":"https://n8layman.github.io/ohseer/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"https://n8layman.github.io/ohseer/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2026). ohseer: Multi-Provider OCR API Interface R. R package version 0.0.0.9000, https://n8layman.github.io/ohseer/.","code":"@Manual{,   title = {ohseer: Multi-Provider OCR API Interface for R},   author = {First Last},   year = {2026},   note = {R package version 0.0.0.9000},   url = {https://n8layman.github.io/ohseer/}, }"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"ohseer","dir":"","previous_headings":"","what":"Multi-Provider OCR API Interface for R","title":"Multi-Provider OCR API Interface for R","text":"unified R interface multiple OCR (Optical Character Recognition) APIs. Process documents Claude (Opus 4.6/Sonnet 4.5), Mistral OCR 3, Tensorlake, AWS Textract using single, consistent function.","code":""},{"path":"https://n8layman.github.io/ohseer/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Multi-Provider OCR API Interface for R","text":"📚 Full documentation: https://n8layman.github.io/ohseer/ Getting Started Guide Provider-Specific Documentation","code":""},{"path":"https://n8layman.github.io/ohseer/index.html","id":"part-of-the-ecoextract-suite","dir":"","previous_headings":"","what":"Part of the EcoExtract Suite","title":"Multi-Provider OCR API Interface for R","text":"OhSeeR foundational first step EcoExtract Suite, collection R packages designed extracting structuring ecological data academic literature. Workflow: Source PDF Documents → OhSeeR (OCR) → sanitizeR (text cleaning) → whispeR (prompts) → LLM API → structuR (structured data) → auditR (validation) → Structured Dataset","code":""},{"path":"https://n8layman.github.io/ohseer/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Multi-Provider OCR API Interface for R","text":"Unified interface: Use ohseer_ocr() provider Provider fallback: Automatic failover one provider fails Claude Opus 4.6: #1 OCR Arena leaderboards, structured outputs JSON schemas Tensorlake: Highest accuracy (91.7%), best tables forms Mistral OCR 3: Native markdown output, cost-effective AWS Textract: Reliable option structured data extraction Consistent output: interface across providers Lightweight: heavy dependencies, uses httr2 API calls","code":""},{"path":"https://n8layman.github.io/ohseer/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Multi-Provider OCR API Interface for R","text":"","code":"# Using pak (recommended) pak::pak(\"n8layman/ohseer\")  # Using devtools devtools::install_github(\"n8layman/ohseer\")  # Using remotes remotes::install_github(\"n8layman/ohseer\")"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"authentication","dir":"","previous_headings":"","what":"Authentication","title":"Multi-Provider OCR API Interface for R","text":"Set API keys environment variables: create .env file project directory: ⚠️ Security: Never commit .env files version control. Add .env .gitignore.","code":"# Set for the current session Sys.setenv(   ANTHROPIC_API_KEY = \"your-claude-key\",        # For Claude   TENSORLAKE_API_KEY = \"your-tensorlake-key\",   # For Tensorlake   MISTRAL_API_KEY = \"your-mistral-key\",         # For Mistral   AWS_ACCESS_KEY_ID = \"your-aws-key\",           # For AWS Textract   AWS_SECRET_ACCESS_KEY = \"your-aws-secret\"     # For AWS Textract ) # .env ANTHROPIC_API_KEY=your-claude-key TENSORLAKE_API_KEY=your-tensorlake-key MISTRAL_API_KEY=your-mistral-key AWS_ACCESS_KEY_ID=your-aws-key AWS_SECRET_ACCESS_KEY=your-aws-secret"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"getting-api-keys","dir":"","previous_headings":"Authentication","what":"Getting API Keys","title":"Multi-Provider OCR API Interface for R","text":"Claude: console.anthropic.com → API Keys Tensorlake: cloud.tensorlake.ai → Dashboard → API Key Mistral: mistral.ai → Try API → API keys AWS Textract: aws.amazon.com → IAM → Create access key AmazonTextractFullAccess","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/index.html","id":"basic-usage","dir":"","previous_headings":"Quick Start","what":"Basic Usage","title":"Multi-Provider OCR API Interface for R","text":"","code":"library(ohseer)  # Process with default provider (Tensorlake) result <- ohseer_ocr(\"document.pdf\")  # Access extracted pages pages <- result$pages provider_used <- result$provider"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"choose-a-specific-provider","dir":"","previous_headings":"Quick Start","what":"Choose a Specific Provider","title":"Multi-Provider OCR API Interface for R","text":"","code":"# Use Claude for highest accuracy result <- ohseer_ocr(\"document.pdf\", provider = \"claude\")  # Use Mistral for cost-effectiveness result <- ohseer_ocr(\"document.pdf\", provider = \"mistral\")  # Use Tensorlake for best table extraction result <- ohseer_ocr(\"document.pdf\", provider = \"tensorlake\")"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"provider-fallback","dir":"","previous_headings":"Quick Start","what":"Provider Fallback","title":"Multi-Provider OCR API Interface for R","text":"Automatically try multiple providers order one succeeds:","code":"# Try Tensorlake first (highest quality), fall back to Mistral (lower cost) result <- ohseer_ocr(   \"document.pdf\",   provider = c(\"tensorlake\", \"mistral\", \"claude\") )  # Check which provider succeeded message(\"Used provider: \", result$provider)  # Check if any providers failed if (!is.na(result$error_log)) {   errors <- jsonlite::fromJSON(result$error_log)   print(errors) }"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"select-specific-pages","dir":"","previous_headings":"Quick Start","what":"Select Specific Pages","title":"Multi-Provider OCR API Interface for R","text":"","code":"# Process only first 2 pages result <- ohseer_ocr(\"document.pdf\", pages = c(1, 2))  # Process specific pages result <- ohseer_ocr(\"document.pdf\", pages = c(1, 5, 10))"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"provider-specific-options","dir":"","previous_headings":"Quick Start","what":"Provider-Specific Options","title":"Multi-Provider OCR API Interface for R","text":"provider accepts custom parameters via ...:","code":"# Mistral: extract headers and footers separately result <- ohseer_ocr(   \"document.pdf\",   provider = \"mistral\",   extract_header = TRUE,   extract_footer = TRUE )  # Claude: use Sonnet instead of Opus, custom schema result <- ohseer_ocr(   \"document.pdf\",   provider = \"claude\",   model = \"claude-sonnet-4-5\",   schema = my_custom_schema )  # Tensorlake: use different model result <- ohseer_ocr(   \"document.pdf\",   provider = \"tensorlake\",   model = \"high-quality-v1\" )"},{"path":"https://n8layman.github.io/ohseer/index.html","id":"output-format","dir":"","previous_headings":"","what":"Output Format","title":"Multi-Provider OCR API Interface for R","text":"providers return consistent structure using ohseer_ocr(): Note: provider returns pages native format. See provider-specific vignettes details: Tensorlake Output Structure Mistral Output Structure Claude Structured Output","code":"result <- ohseer_ocr(\"document.pdf\")  # Result structure: # $provider  - Character: which provider was used # $pages     - List: extracted page data (format varies by provider) # $raw       - List: raw API response # $error_log - Character (JSON): errors from failed providers, or NA"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/index.html","id":"advanced-usage","dir":"","previous_headings":"","what":"Advanced Usage","title":"Multi-Provider OCR API Interface for R","text":"provider-specific functions advanced features, see: Complete Function Reference Unified Interface Guide Provider guides: Tensorlake | Mistral | Claude","code":""},{"path":"https://n8layman.github.io/ohseer/index.html","id":"notes","dir":"","previous_headings":"","what":"Notes","title":"Multi-Provider OCR API Interface for R","text":"package experimental API may change Large files may take time process depending provider Claude API Pricing Tensorlake Pricing Mistral AI Pricing AWS Textract Pricing","code":""},{"path":"https://n8layman.github.io/ohseer/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Multi-Provider OCR API Interface for R","text":"MIT License","code":""},{"path":"https://n8layman.github.io/ohseer/reference/check_api_keys_for_providers.html","id":null,"dir":"Reference","previous_headings":"","what":"Check API Keys for Providers — check_api_keys_for_providers","title":"Check API Keys for Providers — check_api_keys_for_providers","text":"Internal function filter providers API keys available. Warns skipped providers allows cascade continue.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/check_api_keys_for_providers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check API Keys for Providers — check_api_keys_for_providers","text":"","code":"check_api_keys_for_providers(providers)"},{"path":"https://n8layman.github.io/ohseer/reference/check_api_keys_for_providers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check API Keys for Providers — check_api_keys_for_providers","text":"providers Character vector provider names","code":""},{"path":"https://n8layman.github.io/ohseer/reference/check_api_keys_for_providers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check API Keys for Providers — check_api_keys_for_providers","text":"Character vector providers API keys","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_extract_pages.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Page Content from Claude OCR Results — claude_extract_pages","title":"Extract Page Content from Claude OCR Results — claude_extract_pages","text":"Transforms Claude OCR output match Tensorlake's page format. Returns list structure compatible ecoextract downstream tools.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_extract_pages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Page Content from Claude OCR Results — claude_extract_pages","text":"","code":"claude_extract_pages(result, pages = NULL, exclude_types = character(0))"},{"path":"https://n8layman.github.io/ohseer/reference/claude_extract_pages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Page Content from Claude OCR Results — claude_extract_pages","text":"result List. parsed response claude_ocr(). pages Integer vector. Page numbers extract. NULL (default), extracts pages. exclude_types Character vector. Fragment types exclude. Default character(0) (exclusions).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_extract_pages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Page Content from Claude OCR Results — claude_extract_pages","text":"List one element per page, containing: page_number Integer page number page_header Character vector page_header contents section_header Character vector section_header contents text Character string text markdown format tables List tables, markdown, html, content, summary fields List elements type content","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_extract_pages.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Page Content from Claude OCR Results — claude_extract_pages","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_extract_pages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Page Content from Claude OCR Results — claude_extract_pages","text":"","code":"if (FALSE) { # \\dontrun{ # Process document with Claude result <- claude_ocr(\"document.pdf\")  # Extract pages in Tensorlake-compatible format pages <- claude_extract_pages(result)  # Extract specific pages first_two <- claude_extract_pages(result, pages = c(1, 2))  # Use with ecoextract library(ecoextract) json_content <- jsonlite::toJSON(pages, auto_unbox = TRUE) } # }"},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Document with Claude Opus 4.5 OCR — claude_ocr","title":"Process Document with Claude Opus 4.5 OCR — claude_ocr","text":"function processes document Claude Opus 4.5 (#1 OCR Arena leaderboard) returns structured OCR results Tensorlake-compatible format. Claude provides exceptional accuracy complex documents, handwriting, tables, multi-page PDFs.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Document with Claude Opus 4.5 OCR — claude_ocr","text":"","code":"claude_ocr(   file_path,   api_key = Sys.getenv(\"ANTHROPIC_API_KEY\"),   model = \"claude-opus-4-6\",   max_tokens = 16000,   extraction_prompt = NULL,   output_file = NULL )"},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Document with Claude Opus 4.5 OCR — claude_ocr","text":"file_path Character string. Path local PDF, PNG, JPEG, image file. api_key Character string. Anthropic API key. Default retrieves environment variable \"ANTHROPIC_API_KEY\". model Character string. Claude model use. Default \"claude-opus-4-6\". Alternative: \"claude-sonnet-4-5\" faster/cheaper processing. max_tokens Integer. Maximum tokens response. Default 16000. extraction_prompt Character string. Custom extraction prompt. NULL, uses default prompt generates Tensorlake-compatible JSON structure. output_file Character string. Optional path save JSON response file. Default NULL (file output).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Document with Claude Opus 4.5 OCR — claude_ocr","text":"List. parsed response Claude containing: structured_output Parsed JSON pages, tables, structured data content Raw response content Claude usage Token usage information","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process Document with Claude Opus 4.5 OCR — claude_ocr","text":"Claude Opus 4.5 ranks #1 OCR Arena (ELO: 1696, 71.2% win rate) Feb 2026. excels : Complex tables forms Handwritten text Multi-page PDFs Low-quality scans Scientific/technical documents Pricing varies model region. Check Anthropic pricing current rates.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process Document with Claude Opus 4.5 OCR — claude_ocr","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Document with Claude Opus 4.5 OCR — claude_ocr","text":"","code":"if (FALSE) { # \\dontrun{ # Process a PDF with Claude Opus 4.5 result <- claude_ocr(\"document.pdf\")  # Extract pages in Tensorlake format pages <- claude_extract_pages(result)  # Use faster/cheaper Sonnet model result <- claude_ocr(\"document.pdf\", model = \"claude-sonnet-4.5-20250929\")  # Save output to file result <- claude_ocr(\"document.pdf\", output_file = \"ocr_result.json\")  # Use with ecoextract library(ecoextract) pages <- claude_extract_pages(result) json_content <- jsonlite::toJSON(pages, auto_unbox = TRUE) } # }"},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr_process_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Document with Claude OCR — claude_ocr_process_file","title":"Process Document with Claude OCR — claude_ocr_process_file","text":"function processes local PDF image file using Claude's document understanding capabilities returns structured OCR results.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr_process_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Document with Claude OCR — claude_ocr_process_file","text":"","code":"claude_ocr_process_file(   file_path,   api_key = Sys.getenv(\"ANTHROPIC_API_KEY\"),   model = \"claude-opus-4-6\",   max_tokens = 16000,   extraction_prompt = NULL,   endpoint = \"https://api.anthropic.com/v1/messages\" )"},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr_process_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Document with Claude OCR — claude_ocr_process_file","text":"file_path Character string. Path local PDF, PNG, JPEG, supported image file. api_key Character string. Anthropic API key. Default retrieve environment variable \"ANTHROPIC_API_KEY\". model Character string. Claude model use. Default \"claude-opus-4.5-20250514\". max_tokens Integer. Maximum tokens response. Default 16000. extraction_prompt Character string. Custom prompt extraction. NULL, uses default Tensorlake-compatible prompt. endpoint Character string. Claude Messages API endpoint. Default \"https://api.anthropic.com/v1/messages\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr_process_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Document with Claude OCR — claude_ocr_process_file","text":"list containing Claude API response structured OCR data.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/claude_ocr_process_file.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process Document with Claude OCR — claude_ocr_process_file","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_embed_images.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed Base64 Images in Markdown Content — mistral_embed_images","title":"Embed Base64 Images in Markdown Content — mistral_embed_images","text":"function processes markdown content replaces image references embedded base64 data URIs Mistral OCR response object. allows images displayed inline HTML without external files.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_embed_images.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embed Base64 Images in Markdown Content — mistral_embed_images","text":"","code":"mistral_embed_images(markdown_text, mistral_response, page_num = 1)"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_embed_images.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embed Base64 Images in Markdown Content — mistral_embed_images","text":"markdown_text Character string. markdown content process. mistral_response Mistral OCR response object containing pages image data. page_num Integer. page number extract images (default: 1).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_embed_images.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embed Base64 Images in Markdown Content — mistral_embed_images","text":"Character string. processed markdown embedded image data URIs.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_embed_images.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Embed Base64 Images in Markdown Content — mistral_embed_images","text":"function looks image references markdown replaces HTML img tags containing base64-encoded image data. useful rendering OCR results Shiny applications R Markdown documents. Supported image reference patterns: ![img-0.jpeg](img-0.jpeg), ![img-1.jpeg](img-1.jpeg), etc. (Mistral's default format) ![image1], ![image2], etc. ![1], ![2], etc. Generic ![](...) patterns","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_embed_images.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Embed Base64 Images in Markdown Content — mistral_embed_images","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_embed_images.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embed Base64 Images in Markdown Content — mistral_embed_images","text":"","code":"if (FALSE) { # \\dontrun{ # Process markdown with embedded images markdown_with_images <- mistral_embed_images(   markdown_text = ocr_result$pages[[1]]$markdown,   mistral_response = ocr_result,   page_num = 1 ) } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_extract_pages.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Page Content from Mistral OCR Results — mistral_extract_pages","title":"Extract Page Content from Mistral OCR Results — mistral_extract_pages","text":"Returns Mistral's native page output. page includes markdown text, tables, images, headers, footers, dimensional information.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_extract_pages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Page Content from Mistral OCR Results — mistral_extract_pages","text":"","code":"mistral_extract_pages(result, pages = NULL)"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_extract_pages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Page Content from Mistral OCR Results — mistral_extract_pages","text":"result List. parsed response mistral_ocr(). pages Integer vector. Page numbers extract. NULL (default), extracts pages.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_extract_pages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Page Content from Mistral OCR Results — mistral_extract_pages","text":"List one element per page. page contains Mistral's native format: index Integer page index (0-based) markdown Character string page content markdown format header Character string page header (extract_header=TRUE) footer Character string page footer (extract_footer=TRUE) tables List tables id, content, format fields images List images extracted page hyperlinks List hyperlinks detected dimensions Page dimensions (width, height)","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_extract_pages.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Page Content from Mistral OCR Results — mistral_extract_pages","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_extract_pages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Page Content from Mistral OCR Results — mistral_extract_pages","text":"","code":"if (FALSE) { # \\dontrun{ # Process document with Mistral OCR 3 result <- mistral_ocr(   \"document.pdf\",   extract_header = TRUE,   extract_footer = TRUE,   table_format = \"markdown\" )  # Extract all pages pages <- mistral_extract_pages(result)  # Extract specific pages first_two <- mistral_extract_pages(result, pages = c(1, 2))  # Access page content page1_text <- pages[[1]]$markdown page1_tables <- pages[[1]]$tables } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Document with Mistral AI OCR — mistral_ocr","title":"Process Document with Mistral AI OCR — mistral_ocr","text":"function processes document Mistral AI OCR service returns recognized text metadata. automatically detects whether input URL, local file path, file ID.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Document with Mistral AI OCR — mistral_ocr","text":"","code":"mistral_ocr(   input,   input_type = \"auto\",   api_key = Sys.getenv(\"MISTRAL_API_KEY\"),   model = \"mistral-ocr-2512\",   include_image_base64 = TRUE,   document_annotation_format = NULL,   document_annotation_prompt = NULL,   table_format = \"markdown\",   extract_header = TRUE,   extract_footer = TRUE,   output_file = NULL,   timeout = 60,   ... )"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Document with Mistral AI OCR — mistral_ocr","text":"input Either character string URL, path local file, file ID previous upload. input_type Character string. Type input: \"auto\", \"url\", \"file\", \"file_id\". Default \"auto\". api_key Character string. Mistral AI API key. Default retrieve environment variable \"MISTRAL_API_KEY\". model Character string. model use OCR processing. Default \"mistral-ocr-2512\". include_image_base64 Logical. Whether include base64-encoded images response. Default TRUE. document_annotation_format List. Optional structured output format specification. Use list(type = \"json_schema\", json_schema = schema) structured extraction. document_annotation_prompt Character string. Optional prompt guide structured extraction. table_format Character string. Format tables: \"markdown\" \"html\". Default \"markdown\". extract_header Logical. Whether extract page headers separately. Default TRUE. extract_footer Logical. Whether extract page footers separately. Default TRUE. output_file Character string. Optional path save JSON response file. Default NULL (file output). timeout Numeric. Timeout seconds file upload operations. Default 60.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Document with Mistral AI OCR — mistral_ocr","text":"List. parsed response Mistral AI OCR API containing recognized text metadata.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process Document with Mistral AI OCR — mistral_ocr","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Document with Mistral AI OCR — mistral_ocr","text":"","code":"if (FALSE) { # \\dontrun{ # Process a document with auto-detection of input type result <- mistral_ocr(\"https://arxiv.org/pdf/2201.04234\") result <- mistral_ocr(\"path/to/local/document.pdf\") result <- mistral_ocr(\"00edaf84-95b0-45db-8f83-f71138491f23\")  # Explicitly specify input type result <- mistral_ocr(\"https://arxiv.org/pdf/2201.04234\", input_type = \"url\") } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve File Metadata from Mistral AI API — mistral_ocr_get_file_metadata","title":"Retrieve File Metadata from Mistral AI API — mistral_ocr_get_file_metadata","text":"function retrieves file metadata Mistral AI API using file ID.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve File Metadata from Mistral AI API — mistral_ocr_get_file_metadata","text":"","code":"mistral_ocr_get_file_metadata(   file_id,   api_key = Sys.getenv(\"MISTRAL_API_KEY\"),   endpoint_base = \"https://api.mistral.ai/v1\" )"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve File Metadata from Mistral AI API — mistral_ocr_get_file_metadata","text":"file_id Character string. ID file retrieve. api_key Character string. Mistral AI API key. Default retrieve environment variable \"MISTRAL_API_KEY\". endpoint_base Character string. Base URL Mistral AI API. Default \"https://api.mistral.ai/v1\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve File Metadata from Mistral AI API — mistral_ocr_get_file_metadata","text":"list containing file metadata API response.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_metadata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Retrieve File Metadata from Mistral AI API — mistral_ocr_get_file_metadata","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve File Metadata from Mistral AI API — mistral_ocr_get_file_metadata","text":"","code":"if (FALSE) { # \\dontrun{ # Retrieve file metadata file_metadata <- mistral_ocr_get_file_metadata(\"00edaf84-95b0-45db-8f83-f71138491f23\")  # Use a custom API endpoint file_metadata <- mistral_ocr_get_file_metadata(\"00edaf84-95b0-45db-8f83-f71138491f23\",                                          endpoint_base = \"https://api.custom-mistral.ai/v1\") } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Temporary URL for Downloading File from Mistral AI API — mistral_ocr_get_file_url","title":"Get Temporary URL for Downloading File from Mistral AI API — mistral_ocr_get_file_url","text":"function obtains temporary download URL file stored Mistral AI service.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Temporary URL for Downloading File from Mistral AI API — mistral_ocr_get_file_url","text":"","code":"mistral_ocr_get_file_url(   file_id,   expiry = 24,   api_key = Sys.getenv(\"MISTRAL_API_KEY\"),   endpoint_base = \"https://api.mistral.ai/v1\" )"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Temporary URL for Downloading File from Mistral AI API — mistral_ocr_get_file_url","text":"file_id Character string. ID file download. expiry Numeric. number hours URL remain valid. Default 24. api_key Character string. Mistral AI API key. Default retrieve environment variable \"MISTRAL_API_KEY\". endpoint_base Character string. Base URL Mistral AI API. Default \"https://api.mistral.ai/v1\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Temporary URL for Downloading File from Mistral AI API — mistral_ocr_get_file_url","text":"list containing temporary URL related metadata.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_url.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Temporary URL for Downloading File from Mistral AI API — mistral_ocr_get_file_url","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_url.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Temporary URL for Downloading File from Mistral AI API — mistral_ocr_get_file_url","text":"","code":"if (FALSE) { # \\dontrun{ # Get a temporary URL that expires in 24 hours url_data <- mistral_ocr_get_file_url(\"00edaf84-95b0-45db-8f83-f71138491f23\")  # Get a temporary URL that expires in 48 hours url_data <- mistral_ocr_get_file_url(\"00edaf84-95b0-45db-8f83-f71138491f23\", expiry = 48) } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_image.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform OCR on an Image using Mistral AI — mistral_ocr_process_image","title":"Perform OCR on an Image using Mistral AI — mistral_ocr_process_image","text":"function sends image Mistral AI Optical Character Recognition (OCR) returns extracted text layout information.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform OCR on an Image using Mistral AI — mistral_ocr_process_image","text":"","code":"mistral_ocr_process_image(   image_url,   model = \"mistral-ocr-latest\",   include_image_base64 = TRUE,   api_key = Sys.getenv(\"MISTRAL_API_KEY\"),   endpoint = \"https://api.mistral.ai/v1/ocr\" )"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_image.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform OCR on an Image using Mistral AI — mistral_ocr_process_image","text":"image_url Character string. URL image process OCR. model Character string. OCR model use. Default \"mistral-ocr-latest\". include_image_base64 Logical. Whether include base64-encoded images response. Default TRUE. api_key Character string. Mistral AI API key. Default retrieve environment variable \"MISTRAL_API_KEY\". endpoint Character string. OCR API endpoint. Default \"https://api.mistral.ai/v1/ocr\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_image.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform OCR on an Image using Mistral AI — mistral_ocr_process_image","text":"list containing OCR results, including extracted text layout information.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_image.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Perform OCR on an Image using Mistral AI — mistral_ocr_process_image","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_image.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform OCR on an Image using Mistral AI — mistral_ocr_process_image","text":"","code":"if (FALSE) { # \\dontrun{ # Perform OCR on an image from a URL ocr_results <- mistral_ocr_process_image(\"https://example.com/receipt.png\") } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform OCR on a Document using Mistral AI — mistral_ocr_process_url","title":"Perform OCR on a Document using Mistral AI — mistral_ocr_process_url","text":"function sends document Mistral AI Optical Character Recognition (OCR) returns extracted text layout information.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform OCR on a Document using Mistral AI — mistral_ocr_process_url","text":"","code":"mistral_ocr_process_url(   document_url,   model = \"mistral-ocr-2512\",   include_image_base64 = TRUE,   document_annotation_format = NULL,   document_annotation_prompt = NULL,   table_format = \"markdown\",   extract_header = TRUE,   extract_footer = TRUE,   api_key = Sys.getenv(\"MISTRAL_API_KEY\"),   endpoint = \"https://api.mistral.ai/v1/ocr\" )"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform OCR on a Document using Mistral AI — mistral_ocr_process_url","text":"document_url Character string. URL document process OCR. model Character string. OCR model use. Default \"mistral-ocr-2512\". include_image_base64 Logical. Whether include base64-encoded images response. Default TRUE. document_annotation_format List. Optional structured output format specification. Use list(type = \"json_schema\", json_schema = schema) structured extraction. document_annotation_prompt Character string. Optional prompt guide structured extraction. table_format Character string. Format tables: \"markdown\" \"html\". Default \"markdown\". extract_header Logical. Whether extract page headers separately. Default TRUE. available OCR 2512 (OCR 3) newer. extract_footer Logical. Whether extract page footers separately. Default TRUE. available OCR 2512 (OCR 3) newer. api_key Character string. Mistral AI API key. Default retrieve environment variable \"MISTRAL_API_KEY\". endpoint Character string. OCR API endpoint. Default \"https://api.mistral.ai/v1/ocr\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform OCR on a Document using Mistral AI — mistral_ocr_process_url","text":"list containing OCR results, including extracted text layout information.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_process_url.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Perform OCR on a Document using Mistral AI — mistral_ocr_process_url","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_upload_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload File to Mistral AI API for OCR Processing — mistral_ocr_upload_file","title":"Upload File to Mistral AI API for OCR Processing — mistral_ocr_upload_file","text":"function uploads local file Mistral AI API OCR processing. sends file multipart form upload authorization header. can enable verbose mode get detailed HTTP request response info debugging.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_upload_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload File to Mistral AI API for OCR Processing — mistral_ocr_upload_file","text":"","code":"mistral_ocr_upload_file(   file_path,   purpose = \"ocr\",   api_key = Sys.getenv(\"MISTRAL_API_KEY\"),   endpoint = \"https://api.mistral.ai/v1/files\",   verbose = FALSE,   timeout = 60 )"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_upload_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload File to Mistral AI API for OCR Processing — mistral_ocr_upload_file","text":"file_path Character string. Path local file upload. purpose Character string. purpose file uploaded. Default \"ocr\". api_key Character string. Mistral AI API key. Default retrieve environment variable \"MISTRAL_API_KEY\". endpoint Character string. Mistral AI API endpoint URL. Default \"https://api.mistral.ai/v1/files\". verbose Logical. TRUE, enables verbose HTTP request/response logging debugging. Default FALSE. timeout Numeric. Timeout seconds upload request. Default 60.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_upload_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload File to Mistral AI API for OCR Processing — mistral_ocr_upload_file","text":"List. Parsed JSON response Mistral AI API containing file metadata including file ID.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_upload_file.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Upload File to Mistral AI API for OCR Processing — mistral_ocr_upload_file","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_ocr_upload_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload File to Mistral AI API for OCR Processing — mistral_ocr_upload_file","text":"","code":"if (FALSE) { # \\dontrun{ # Upload a local PDF file result <- mistral_ocr_upload_file(\"path/to/document.pdf\")  # Use the returned file ID for OCR processing file_id <- result$id  # Enable verbose mode to debug upload issues result <- mistral_ocr_upload_file(\"path/to/document.pdf\", verbose = TRUE)  # Specify a custom endpoint result <- mistral_ocr_upload_file(\"path/to/document.pdf\",                                   endpoint = \"https://api.custom-mistral.ai/v1/files\") } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_html.html","id":null,"dir":"Reference","previous_headings":"","what":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","title":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","text":"function creates complete HTML preview Mistral OCR page embedded images. Unlike mistral_preview_page(), function embeds images directly HTML using base64 data URIs, eliminating need magick package.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","text":"","code":"mistral_preview_html(mistral_obj, page_num = 1)"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","text":"mistral_obj Mistral OCR object containing pages markdown content images. page_num Integer. page number preview (default: 1).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_html.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","text":"browsable HTML widget displaying rendered page content embedded images.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_html.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","text":"function combines markdown rendering image embedding create complete, self-contained HTML preview. Images embedded base64 data URIs, external files image processing libraries required.","code":""},{"path":[]},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_html.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_html.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preview Mistral OCR Page as HTML with Embedded Images — mistral_preview_html","text":"","code":"if (FALSE) { # \\dontrun{ # Preview the first page of an OCR result result <- mistral_ocr(\"document.pdf\") mistral_preview_html(result, page_num = 1)  # Use in Shiny output$ocr_preview <- renderUI({   mistral_preview_html(ocr_result()) }) } # }"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_page.html","id":null,"dir":"Reference","previous_headings":"","what":"Preview Mistral OCR Page as HTML — mistral_preview_page","title":"Preview Mistral OCR Page as HTML — mistral_preview_page","text":"function converts markdown content Mistral OCR object page HTML displays browsable format.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_page.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preview Mistral OCR Page as HTML — mistral_preview_page","text":"","code":"mistral_preview_page(mistral_obj, page_num = 1)"},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_page.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preview Mistral OCR Page as HTML — mistral_preview_page","text":"mistral_obj Mistral OCR object containing pages markdown content. page_num page number preview (default: 1).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_page.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preview Mistral OCR Page as HTML — mistral_preview_page","text":"browsable HTML widget displaying rendered page content.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_page.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Preview Mistral OCR Page as HTML — mistral_preview_page","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/mistral_preview_page.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preview Mistral OCR Page as HTML — mistral_preview_page","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming test_mistral is a Mistral OCR object mistral_preview_page(test_mistral, 1) } # }"},{"path":[]},{"path":"https://n8layman.github.io/ohseer/reference/ohseer_ocr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified OCR Interface for Multiple Providers with Automatic Fallback — ohseer_ocr","text":"","code":"ohseer_ocr(   file_path,   provider = c(\"tensorlake\", \"mistral\", \"claude\"),   pages = NULL,   timeout = 60,   extract_pages = TRUE,   ... )"},{"path":"https://n8layman.github.io/ohseer/reference/ohseer_ocr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified OCR Interface for Multiple Providers with Automatic Fallback — ohseer_ocr","text":"file_path Character string. Path PDF file process. provider Character vector. OCR provider(s) use. Can single provider multiple providers automatic fallback. Valid values: \"tensorlake\" Tensorlake OCR API (default) - Highest accuracy (91.7\\ \"mistral\"Mistral OCR 3 - Lower cost, native markdown format \"claude\"Claude Opus/Sonnet - Structured outputs JSON schema pagesInteger vector. Specific page numbers process. NULL (default), processes pages. Page numbers 1-based. timeoutNumeric. Maximum wait time seconds OCR processing. Default 60 seconds. used Claude provider. extract_pagesLogical. TRUE (default), automatically extracts returns page data using provider-specific extraction functions. FALSE, returns raw API response. ...Additional provider-specific arguments passed underlying OCR function: Tensorlake model, use_cache, etc. Mistral extract_header, extract_footer, table_format, etc. Claude model, max_tokens, dpi, schema, etc. extract_pages = TRUE (default), returns list : provider Character string naming provider succeeded pages List extracted page data (structure varies provider) raw Raw API response (advanced use) error_log Character string (JSON) failed attempts, NA first provider succeeded page_number: Integer (1-based) page_fragments: List content fragments type, content, reading_order index: Integer (0-based) markdown: Full page content tables: Array table objects header, footer: Separate header/footer fields page_number: Integer (1-based) page_fragments: List content fragments Custom schema can provided via schema argument Provider FallbackWhen multiple providers specified, tried sequentially one succeeds: Provider-specific functions: tensorlake_ocr, tensorlake_extract_pages mistral_ocr, mistral_extract_pages claude_ocr_process_file, claude_extract_pages","code":"# Try Mistral first (lower cost), fall back to Tensorlake (higher quality) result <- ohseer_ocr(\"document.pdf\", provider = c(\"mistral\", \"tensorlake\"))# Try Tensorlake first (higher quality), fall back to Mistral (lower cost) result <- ohseer_ocr(\"document.pdf\", provider = c(\"tensorlake\", \"mistral\"))# Check which provider succeeded message(\"Used provider: \", result$provider)# Check error log if any providers failed if (!is.na(result$error_log)) {   errors <- jsonlite::fromJSON(result$error_log)   print(errors) }"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_extract_pages.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Page Content by Fragment Type — tensorlake_extract_pages","title":"Extract Page Content by Fragment Type — tensorlake_extract_pages","text":"Extracts content Tensorlake OCR results organized fragment type. Returns simple list structure fragments grouped Tensorlake-assigned types (page_header, section_header, text, table, etc.).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_extract_pages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Page Content by Fragment Type — tensorlake_extract_pages","text":"","code":"tensorlake_extract_pages(result, pages = NULL, exclude_types = character(0))"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_extract_pages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Page Content by Fragment Type — tensorlake_extract_pages","text":"result List. parsed response tensorlake_ocr(). pages Integer vector. Page numbers extract. NULL (default), extracts pages. exclude_types Character vector. Fragment types exclude. Default character(0) (exclusions).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_extract_pages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Page Content by Fragment Type — tensorlake_extract_pages","text":"List one element per page, containing: page_number Integer page number page_header Character vector page_header fragment contents section_header Character vector section_header fragment contents text Character string text fragments markdown format tables List tables, markdown, html, content fields List fragment types type content","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_extract_pages.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Page Content by Fragment Type — tensorlake_extract_pages","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_extract_pages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Page Content by Fragment Type — tensorlake_extract_pages","text":"","code":"if (FALSE) { # \\dontrun{ result <- tensorlake_ocr(\"article.pdf\")  # Extract all pages all_pages <- tensorlake_extract_pages(result)  # Extract specific pages first_two <- tensorlake_extract_pages(result, pages = c(1, 2))  # Access first page data page1 <- all_pages[[1]] page1$page_header     # Journal citation page1$section_header  # Article title page1$text           # Body text in markdown page1$tables         # List of tables } # }"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_get_parse_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Parse Result from Tensorlake — tensorlake_get_parse_result","title":"Get Parse Result from Tensorlake — tensorlake_get_parse_result","text":"function retrieves result Tensorlake parse job using parse ID. Tensorlake parsing typically fast, large documents may take seconds.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_get_parse_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Parse Result from Tensorlake — tensorlake_get_parse_result","text":"","code":"tensorlake_get_parse_result(   parse_id,   tensorlake_api_key,   base_url = \"https://api.tensorlake.ai\" )"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_get_parse_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Parse Result from Tensorlake — tensorlake_get_parse_result","text":"parse_id Character string. parse job ID returned tensorlake_parse_document(). tensorlake_api_key Character string. Tensorlake API key. base_url Character string. Base URL Tensorlake API. Default \"https://api.tensorlake.ai\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_get_parse_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Parse Result from Tensorlake — tensorlake_get_parse_result","text":"List containing parsed document data including: status Job status (processing, completed, failed) result Parsed document content text, tables, structured data metadata Document metadata","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_get_parse_result.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Parse Result from Tensorlake — tensorlake_get_parse_result","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_ocr.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Document with Tensorlake OCR — tensorlake_ocr","title":"Process Document with Tensorlake OCR — tensorlake_ocr","text":"function processes document Tensorlake's high-accuracy parsing service (91.7% accuracy) returns OCR results. function uploads file, submits parse job, polls completion, returns final result.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_ocr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Document with Tensorlake OCR — tensorlake_ocr","text":"","code":"tensorlake_ocr(   file_path,   pages = NULL,   tensorlake_api_key = Sys.getenv(\"TENSORLAKE_API_KEY\"),   max_wait_seconds = 60,   poll_interval = 2,   output_file = NULL )"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_ocr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Document with Tensorlake OCR — tensorlake_ocr","text":"file_path Character string. Path local PDF, DOCX, PPTX, image, text file. pages Integer vector character string. Optional page range parse. Can vector like c(1, 2) 1:5, string like \"1-5\" \"1,3,5\". NULL (default), parses entire document. tensorlake_api_key Character string. Tensorlake API key. Default retrieves environment variable \"TENSORLAKE_API_KEY\". max_wait_seconds Numeric. Maximum seconds wait parsing complete. Default 60. poll_interval Numeric. Seconds status checks. Default 2. output_file Character string. Optional path save JSON response file. Default NULL (file output).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_ocr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Document with Tensorlake OCR — tensorlake_ocr","text":"List. parsed response Tensorlake containing: status Parse job status result Parsed document content text, tables, structured data metadata Document metadata","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_ocr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process Document with Tensorlake OCR — tensorlake_ocr","text":"Tensorlake offers superior accuracy (91.7%) compared AWS Textract (88.4%) 5 MB file size limit Textract's synchronous API. Pricing competitive $0.01 per page.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_ocr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process Document with Tensorlake OCR — tensorlake_ocr","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_ocr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Document with Tensorlake OCR — tensorlake_ocr","text":"","code":"if (FALSE) { # \\dontrun{ # Process entire PDF with Tensorlake result <- tensorlake_ocr(\"document.pdf\")  # Process only first 2 pages (faster, cheaper) result <- tensorlake_ocr(\"document.pdf\", pages = c(1, 2))  # Save output to JSON file result <- tensorlake_ocr(\"document.pdf\", output_file = \"result.json\")  # Extract structured data pages <- tensorlake_extract_pages(result, pages = c(1, 2)) } # }"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_parse_document.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse Document with Tensorlake API — tensorlake_parse_document","title":"Parse Document with Tensorlake API — tensorlake_parse_document","text":"function submits document Tensorlake parsing using file ID tensorlake_upload_file(). Tensorlake offers high-accuracy document parsing (91.7% accuracy) support tables, forms, structured data extraction.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_parse_document.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse Document with Tensorlake API — tensorlake_parse_document","text":"","code":"tensorlake_parse_document(   file_id,   tensorlake_api_key,   pages = NULL,   base_url = \"https://api.tensorlake.ai\" )"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_parse_document.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse Document with Tensorlake API — tensorlake_parse_document","text":"file_id Character string. Tensorlake file ID tensorlake_upload_file(). tensorlake_api_key Character string. Tensorlake API key. pages Character string. Optional page range parse (e.g., \"1-5\" \"1,3,5\"). base_url Character string. Base URL Tensorlake API. Default \"https://api.tensorlake.ai\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_parse_document.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse Document with Tensorlake API — tensorlake_parse_document","text":"List containing parse job details including: parse_id Unique ID parse job status Job status (processing, completed, failed) result Parsed document content (completed)","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_parse_document.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parse Document with Tensorlake API — tensorlake_parse_document","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_upload_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload File to Tensorlake — tensorlake_upload_file","title":"Upload File to Tensorlake — tensorlake_upload_file","text":"function uploads file Tensorlake returns file ID can used parsing operations.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_upload_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload File to Tensorlake — tensorlake_upload_file","text":"","code":"tensorlake_upload_file(   file_path,   tensorlake_api_key,   labels = NULL,   base_url = \"https://api.tensorlake.ai\" )"},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_upload_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload File to Tensorlake — tensorlake_upload_file","text":"file_path Character string. Path local file upload. tensorlake_api_key Character string. Tensorlake API key. labels List. Optional metadata labels attach file. base_url Character string. Base URL Tensorlake API. Default \"https://api.tensorlake.ai\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_upload_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload File to Tensorlake — tensorlake_upload_file","text":"List containing: file_id Unique identifier uploaded file","code":""},{"path":"https://n8layman.github.io/ohseer/reference/tensorlake_upload_file.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Upload File to Tensorlake — tensorlake_upload_file","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_analyze_document.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze Document with AWS Textract (Synchronous, Structured Extraction) — textract_analyze_document","title":"Analyze Document with AWS Textract (Synchronous, Structured Extraction) — textract_analyze_document","text":"function calls AWS Textract AnalyzeDocument API (synchronous) extract structured data including forms (key-value pairs), tables, layout documents. Note: synchronous operation 5 MB file size limit. larger files, function automatically converts first 2 pages PNG format.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_analyze_document.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze Document with AWS Textract (Synchronous, Structured Extraction) — textract_analyze_document","text":"","code":"textract_analyze_document(   file_path,   features = c(\"TABLES\", \"FORMS\"),   aws_access_key_id,   aws_secret_access_key,   aws_region = \"us-east-1\" )"},{"path":"https://n8layman.github.io/ohseer/reference/textract_analyze_document.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze Document with AWS Textract (Synchronous, Structured Extraction) — textract_analyze_document","text":"file_path Character string. Path local PDF, PNG, JPEG, TIFF file. features Character vector. Features extract: \"TABLES\", \"FORMS\", \"LAYOUT\", \"SIGNATURES\". aws_access_key_id Character string. AWS access key ID. aws_secret_access_key Character string. AWS secret access key. aws_region Character string. AWS region. Default \"us-east-1\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_analyze_document.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze Document with AWS Textract (Synchronous, Structured Extraction) — textract_analyze_document","text":"List containing raw Textract API response Blocks.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_analyze_document.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Analyze Document with AWS Textract (Synchronous, Structured Extraction) — textract_analyze_document","text":"function uses synchronous Textract API 5 MB file size limit. PDFs larger 5 MB, first 2 pages automatically extracted converted PNG format. full document processing large files, consider using asynchronous S3-based Textract workflow alternative service like Google Document AI (20 MB limit) Azure Document Intelligence (500 MB limit).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_analyze_document.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analyze Document with AWS Textract (Synchronous, Structured Extraction) — textract_analyze_document","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_detect_document_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Text in Document with AWS Textract (Synchronous) — textract_detect_document_text","title":"Detect Text in Document with AWS Textract (Synchronous) — textract_detect_document_text","text":"function calls AWS Textract DetectDocumentText API (synchronous) extract plain text documents. faster AnalyzeDocument extract structured data like forms tables. Note: synchronous operation 5 MB file size limit. larger files, function automatically converts first 2 pages PNG format.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_detect_document_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Text in Document with AWS Textract (Synchronous) — textract_detect_document_text","text":"","code":"textract_detect_document_text(   file_path,   aws_access_key_id,   aws_secret_access_key,   aws_region = \"us-east-1\" )"},{"path":"https://n8layman.github.io/ohseer/reference/textract_detect_document_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Text in Document with AWS Textract (Synchronous) — textract_detect_document_text","text":"file_path Character string. Path local PDF, PNG, JPEG, TIFF file. aws_access_key_id Character string. AWS access key ID. aws_secret_access_key Character string. AWS secret access key. aws_region Character string. AWS region. Default \"us-east-1\".","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_detect_document_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Text in Document with AWS Textract (Synchronous) — textract_detect_document_text","text":"List containing raw Textract API response Blocks.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_detect_document_text.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Detect Text in Document with AWS Textract (Synchronous) — textract_detect_document_text","text":"function uses synchronous Textract API 5 MB file size limit. PDFs larger 5 MB, first 2 pages automatically extracted converted PNG format. full document processing large files, consider using asynchronous S3-based Textract workflow alternative service like Google Document AI (20 MB limit) Azure Document Intelligence (500 MB limit).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_detect_document_text.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Detect Text in Document with AWS Textract (Synchronous) — textract_detect_document_text","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_key_value_pairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Key-Value Pairs from Textract Blocks — textract_extract_key_value_pairs","title":"Extract Key-Value Pairs from Textract Blocks — textract_extract_key_value_pairs","text":"Extract Key-Value Pairs Textract Blocks","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_key_value_pairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Key-Value Pairs from Textract Blocks — textract_extract_key_value_pairs","text":"","code":"textract_extract_key_value_pairs(blocks)"},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_key_value_pairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Key-Value Pairs from Textract Blocks — textract_extract_key_value_pairs","text":"blocks List Textract blocks","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_key_value_pairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Key-Value Pairs from Textract Blocks — textract_extract_key_value_pairs","text":"Data frame key-value pairs NULL","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Metadata from AWS Textract Response — textract_extract_metadata","title":"Extract Metadata from AWS Textract Response — textract_extract_metadata","text":"convenience function parses AWS Textract output extract citation metadata structured information document headers. Useful extracting titles, authors, DOIs, journal names, dates, etc. academic papers.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Metadata from AWS Textract Response — textract_extract_metadata","text":"","code":"textract_extract_metadata(textract_response)"},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Metadata from AWS Textract Response — textract_extract_metadata","text":"textract_response List. Response textract_ocr().","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Metadata from AWS Textract Response — textract_extract_metadata","text":"List following structure: text Character string. Full document text line breaks. key_value_pairs Data frame columns: key, value, confidence. Contains extracted metadata like \"Title:\", \"Author:\", etc. tables List data frames, one per table. pages Integer. Number pages processed.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_metadata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Metadata from AWS Textract Response — textract_extract_metadata","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Metadata from AWS Textract Response — textract_extract_metadata","text":"","code":"if (FALSE) { # \\dontrun{ # Process document with Textract result <- textract_ocr(\"paper.pdf\")  # Extract citation metadata metadata <- textract_extract_metadata(result)  # Access extracted key-value pairs (e.g., Title, Authors, DOI) metadata$key_value_pairs } # }"},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Tables from Textract Blocks — textract_extract_tables","title":"Extract Tables from Textract Blocks — textract_extract_tables","text":"Extract Tables Textract Blocks","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Tables from Textract Blocks — textract_extract_tables","text":"","code":"textract_extract_tables(blocks)"},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Tables from Textract Blocks — textract_extract_tables","text":"blocks List Textract blocks","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_extract_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Tables from Textract Blocks — textract_extract_tables","text":"List data frames (one per table) NULL","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_get_block_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Text Content from a Textract Block — textract_get_block_text","title":"Get Text Content from a Textract Block — textract_get_block_text","text":"Get Text Content Textract Block","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_get_block_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Text Content from a Textract Block — textract_get_block_text","text":"","code":"textract_get_block_text(block, blocks)"},{"path":"https://n8layman.github.io/ohseer/reference/textract_get_block_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Text Content from a Textract Block — textract_get_block_text","text":"block Textract block blocks blocks reference","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_get_block_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Text Content from a Textract Block — textract_get_block_text","text":"Character string block text","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_ocr.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","title":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","text":"function processes document AWS Textract service (synchronous API) returns OCR results. alternative mistral_ocr() provides better structured output forms tables. Note: uses synchronous processing 5 MB file size limit. larger PDFs, function automatically converts first 2 pages PNG format.","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_ocr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","text":"","code":"textract_ocr(   file_path,   features = c(\"TABLES\", \"FORMS\"),   aws_access_key_id = Sys.getenv(\"AWS_ACCESS_KEY_ID\"),   aws_secret_access_key = Sys.getenv(\"AWS_SECRET_ACCESS_KEY\"),   aws_region = Sys.getenv(\"AWS_REGION\", unset = \"us-east-1\"),   max_pages = 2,   output_file = NULL )"},{"path":"https://n8layman.github.io/ohseer/reference/textract_ocr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","text":"file_path Character string. Path local PDF, PNG, JPEG, TIFF file. features Character vector. Features extract. Options: \"TABLES\", \"FORMS\", \"LAYOUT\", \"SIGNATURES\". Default c(\"TABLES\", \"FORMS\") structured extraction. Set NULL simple text extraction. aws_access_key_id Character string. AWS access key ID. Default retrieves environment variable \"AWS_ACCESS_KEY_ID\". aws_secret_access_key Character string. AWS secret access key. Default retrieves environment variable \"AWS_SECRET_ACCESS_KEY\". aws_region Character string. AWS region. Default retrieves environment variable \"AWS_REGION\" \"us-east-1\" set. max_pages Integer. Maximum number pages process large PDFs. Default 2. Set NULL process pages (chunk automatically). output_file Character string. Optional path save JSON response file. Default NULL (file output).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_ocr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","text":"List. parsed response AWS Textract containing: Blocks List detected blocks (text, tables, forms, etc.) DocumentMetadata Metadata document","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_ocr.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","text":"function uses synchronous Textract API 5 MB file size limit. PDFs larger 5 MB, first 2 pages automatically extracted converted PNG format. full document processing large files, consider using asynchronous S3-based Textract workflow alternative service like Google Document AI (20 MB limit) Azure Document Intelligence (500 MB limit).","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_ocr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","text":"Nathan C. Layman","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_ocr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Document with AWS Textract OCR (Synchronous) — textract_ocr","text":"","code":"if (FALSE) { # \\dontrun{ # Process a PDF with structured extraction (tables and forms) result <- textract_ocr(\"document.pdf\")  # Just extract text (faster, no structured data) result <- textract_ocr(\"document.pdf\", features = NULL)  # Extract citation metadata from the result metadata <- textract_extract_metadata(result)  # Save output to JSON file result <- textract_ocr(\"document.pdf\", output_file = \"result.json\") } # }"},{"path":"https://n8layman.github.io/ohseer/reference/textract_parse_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse a Single Table from Textract Blocks — textract_parse_table","title":"Parse a Single Table from Textract Blocks — textract_parse_table","text":"Parse Single Table Textract Blocks","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_parse_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse a Single Table from Textract Blocks — textract_parse_table","text":"","code":"textract_parse_table(table_block, blocks)"},{"path":"https://n8layman.github.io/ohseer/reference/textract_parse_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse a Single Table from Textract Blocks — textract_parse_table","text":"table_block Textract TABLE block blocks blocks reference","code":""},{"path":"https://n8layman.github.io/ohseer/reference/textract_parse_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse a Single Table from Textract Blocks — textract_parse_table","text":"Data frame representing table","code":""}]
