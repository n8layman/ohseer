# ohseer

A unified R interface to multiple OCR (Optical Character Recognition)
APIs. Process documents with Claude (Opus 4.6/Sonnet 4.5), Mistral OCR
3, Tensorlake, or AWS Textract using a single, consistent function.

## Documentation

üìö **Full documentation**: <https://n8layman.github.io/ohseer/>

- [Getting Started
  Guide](https://n8layman.github.io/ohseer/articles/unified-interface.html)
- [Provider-Specific
  Documentation](https://n8layman.github.io/ohseer/reference/index.html)

## Part of the EcoExtract Suite

`OhSeeR` is the foundational first step in the **EcoExtract Suite**, a
collection of R packages designed for extracting and structuring
ecological data from academic literature.

**Workflow**: Source PDF Documents ‚Üí **OhSeeR** (OCR) ‚Üí sanitizeR (text
cleaning) ‚Üí whispeR (prompts) ‚Üí LLM API ‚Üí structuR (structured data) ‚Üí
auditR (validation) ‚Üí Structured Dataset

## Features

- **Unified interface**: Use
  [`ohseer_ocr()`](https://n8layman.github.io/ohseer/reference/ohseer_ocr.md)
  with any provider
- **Provider fallback**: Automatic failover if one provider fails
- **Multiple OCR providers**:
  - **Claude Opus 4.6**: \#1 on OCR Arena leaderboards, structured
    outputs with JSON schemas
  - **Tensorlake**: Highest accuracy (91.7%), best for tables and forms
  - **Mistral OCR 3**: Native markdown output, cost-effective
  - **AWS Textract**: Reliable option for structured data extraction
- **Consistent output**: Same interface across all providers
- **Lightweight**: No heavy dependencies, uses httr2 for all API calls

## Installation

``` r
# Using pak (recommended)
pak::pak("n8layman/ohseer")

# Using devtools
devtools::install_github("n8layman/ohseer")

# Using remotes
remotes::install_github("n8layman/ohseer")
```

## Authentication

Set up API keys as environment variables:

``` r
# Set for the current session
Sys.setenv(
  ANTHROPIC_API_KEY = "your-claude-key",        # For Claude
  TENSORLAKE_API_KEY = "your-tensorlake-key",   # For Tensorlake
  MISTRAL_API_KEY = "your-mistral-key",         # For Mistral
  AWS_ACCESS_KEY_ID = "your-aws-key",           # For AWS Textract
  AWS_SECRET_ACCESS_KEY = "your-aws-secret"     # For AWS Textract
)
```

Or create a `.env` file in your project directory:

``` bash
# .env
ANTHROPIC_API_KEY=your-claude-key
TENSORLAKE_API_KEY=your-tensorlake-key
MISTRAL_API_KEY=your-mistral-key
AWS_ACCESS_KEY_ID=your-aws-key
AWS_SECRET_ACCESS_KEY=your-aws-secret
```

‚ö†Ô∏è **Security**: Never commit `.env` files to version control. Add
`.env` to your `.gitignore`.

### Getting API Keys

- **Claude**: [console.anthropic.com](https://console.anthropic.com/) ‚Üí
  API Keys
- **Tensorlake**: [cloud.tensorlake.ai](https://cloud.tensorlake.ai/) ‚Üí
  Dashboard ‚Üí API Key
- **Mistral**: [mistral.ai](https://mistral.ai/) ‚Üí Try the API ‚Üí API
  keys
- **AWS Textract**: [aws.amazon.com](https://aws.amazon.com/) ‚Üí IAM ‚Üí
  Create access key with `AmazonTextractFullAccess`

## Quick Start

### Basic Usage

``` r
library(ohseer)

# Process with default provider (Tensorlake)
result <- ohseer_ocr("document.pdf")

# Access extracted pages
pages <- result$pages
provider_used <- result$provider
```

### Choose a Specific Provider

``` r
# Use Claude for highest accuracy
result <- ohseer_ocr("document.pdf", provider = "claude")

# Use Mistral for cost-effectiveness
result <- ohseer_ocr("document.pdf", provider = "mistral")

# Use Tensorlake for best table extraction
result <- ohseer_ocr("document.pdf", provider = "tensorlake")
```

### Provider Fallback

Automatically try multiple providers in order until one succeeds:

``` r
# Try Tensorlake first (highest quality), fall back to Mistral (lower cost)
result <- ohseer_ocr(
  "document.pdf",
  provider = c("tensorlake", "mistral", "claude")
)

# Check which provider succeeded
message("Used provider: ", result$provider)

# Check if any providers failed
if (!is.na(result$error_log)) {
  errors <- jsonlite::fromJSON(result$error_log)
  print(errors)
}
```

### Select Specific Pages

``` r
# Process only first 2 pages
result <- ohseer_ocr("document.pdf", pages = c(1, 2))

# Process specific pages
result <- ohseer_ocr("document.pdf", pages = c(1, 5, 10))
```

### Provider-Specific Options

Each provider accepts its own custom parameters via `...`:

``` r
# Mistral: extract headers and footers separately
result <- ohseer_ocr(
  "document.pdf",
  provider = "mistral",
  extract_header = TRUE,
  extract_footer = TRUE
)

# Claude: use Sonnet instead of Opus, custom schema
result <- ohseer_ocr(
  "document.pdf",
  provider = "claude",
  model = "claude-sonnet-4-5",
  schema = my_custom_schema
)

# Tensorlake: use different model
result <- ohseer_ocr(
  "document.pdf",
  provider = "tensorlake",
  model = "high-quality-v1"
)
```

## Output Format

All providers return a consistent structure when using
[`ohseer_ocr()`](https://n8layman.github.io/ohseer/reference/ohseer_ocr.md):

``` r
result <- ohseer_ocr("document.pdf")

# Result structure:
# $provider  - Character: which provider was used
# $pages     - List: extracted page data (format varies by provider)
# $raw       - List: raw API response
# $error_log - Character (JSON): errors from failed providers, or NA
```

**Note**: Each provider returns pages in its own native format. See
provider-specific vignettes for details:

- [Tensorlake Output
  Structure](https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html)
- [Mistral Output
  Structure](https://n8layman.github.io/ohseer/articles/mistral-output-structure.html)
- [Claude Structured
  Output](https://n8layman.github.io/ohseer/articles/claude-structured-output.html)

## Provider Comparison

| Provider            | Accuracy                  | Speed     | Cost        | Best For                           |
|---------------------|---------------------------|-----------|-------------|------------------------------------|
| **Claude Opus 4.6** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (#1 OCR Arena) | Medium    | High        | Structured outputs, custom schemas |
| **Tensorlake**      | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (91.7%)        | Fast      | \$0.01/page | Tables, forms, batch processing    |
| **Mistral OCR 3**   | ‚≠ê‚≠ê‚≠ê                    | Very Fast | Low         | Markdown output, cost-sensitive    |
| **AWS Textract**    | ‚≠ê‚≠ê‚≠ê‚≠ê (88.4%)          | Fast      | Medium      | AWS ecosystem, reliability         |

## Advanced Usage

For provider-specific functions and advanced features, see:

- [Complete Function
  Reference](https://n8layman.github.io/ohseer/reference/index.html)
- [Unified Interface
  Guide](https://n8layman.github.io/ohseer/articles/unified-interface.html)
- Provider guides:
  [Tensorlake](https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.html)
  \|
  [Mistral](https://n8layman.github.io/ohseer/articles/mistral-output-structure.html)
  \|
  [Claude](https://n8layman.github.io/ohseer/articles/claude-structured-output.html)

## Notes

- This package is experimental and the API may change
- Large files may take time to process depending on provider
- Check provider documentation for pricing and rate limits:
  - [Claude API Pricing](https://www.anthropic.com/pricing)
  - [Tensorlake Pricing](https://docs.tensorlake.ai/pricing)
  - [Mistral AI Pricing](https://mistral.ai/technology/#pricing)
  - [AWS Textract Pricing](https://aws.amazon.com/textract/pricing/)

## License

MIT License

# Package index

## Unified Interface

Consistent OCR interface across all providers (recommended)

- [`ohseer_ocr()`](https://n8layman.github.io/ohseer/reference/ohseer_ocr.md)
  : Unified OCR Interface for Multiple Providers with Automatic Fallback

## Tensorlake OCR

Process documents with Tensorlake OCR API

- [`tensorlake_ocr()`](https://n8layman.github.io/ohseer/reference/tensorlake_ocr.md)
  : Process Document with Tensorlake OCR
- [`tensorlake_extract_pages()`](https://n8layman.github.io/ohseer/reference/tensorlake_extract_pages.md)
  : Extract Page Content by Fragment Type

## Mistral OCR

Process documents with Mistral OCR API

- [`mistral_ocr()`](https://n8layman.github.io/ohseer/reference/mistral_ocr.md)
  : Process Document with Mistral AI OCR
- [`mistral_extract_pages()`](https://n8layman.github.io/ohseer/reference/mistral_extract_pages.md)
  : Extract Page Content from Mistral OCR Results
- [`mistral_ocr_upload_file()`](https://n8layman.github.io/ohseer/reference/mistral_ocr_upload_file.md)
  : Upload File to Mistral AI API for OCR Processing
- [`mistral_ocr_get_file_metadata()`](https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_metadata.md)
  : Retrieve File Metadata from Mistral AI API
- [`mistral_ocr_get_file_url()`](https://n8layman.github.io/ohseer/reference/mistral_ocr_get_file_url.md)
  : Get Temporary URL for Downloading File from Mistral AI API
- [`mistral_ocr_process_url()`](https://n8layman.github.io/ohseer/reference/mistral_ocr_process_url.md)
  : Perform OCR on a Document using Mistral AI
- [`mistral_ocr_process_image()`](https://n8layman.github.io/ohseer/reference/mistral_ocr_process_image.md)
  : Perform OCR on an Image using Mistral AI

## Mistral Preview

Generate HTML previews of Mistral OCR results

- [`mistral_preview_page()`](https://n8layman.github.io/ohseer/reference/mistral_preview_page.md)
  : Preview Mistral OCR Page as HTML
- [`mistral_preview_html()`](https://n8layman.github.io/ohseer/reference/mistral_preview_html.md)
  : Preview Mistral OCR Page as HTML with Embedded Images
- [`mistral_embed_images()`](https://n8layman.github.io/ohseer/reference/mistral_embed_images.md)
  : Embed Base64 Images in Markdown Content

## Claude OCR

Process documents with Claude API using structured outputs

- [`claude_ocr()`](https://n8layman.github.io/ohseer/reference/claude_ocr.md)
  : Process Document with Claude Opus 4.5 OCR
- [`claude_extract_pages()`](https://n8layman.github.io/ohseer/reference/claude_extract_pages.md)
  : Extract Page Content from Claude OCR Results

## AWS Textract

Process documents with AWS Textract

- [`textract_ocr()`](https://n8layman.github.io/ohseer/reference/textract_ocr.md)
  : Process Document with AWS Textract OCR (Synchronous)
- [`textract_extract_metadata()`](https://n8layman.github.io/ohseer/reference/textract_extract_metadata.md)
  : Extract Metadata from AWS Textract Response
- [`textract_analyze_document()`](https://n8layman.github.io/ohseer/reference/textract_analyze_document.md)
  : Analyze Document with AWS Textract (Synchronous, Structured
  Extraction)
- [`textract_detect_document_text()`](https://n8layman.github.io/ohseer/reference/textract_detect_document_text.md)
  : Detect Text in Document with AWS Textract (Synchronous)

# Articles

### Getting Started

- [Getting Started with
  ohseer](https://n8layman.github.io/ohseer/articles/unified-interface.md):

### OCR Provider Guides

- [Understanding Tensorlake Output
  Structure](https://n8layman.github.io/ohseer/articles/tensorlake-output-structure.md):
- [Understanding Mistral OCR Output
  Structure](https://n8layman.github.io/ohseer/articles/mistral-output-structure.md):
- [Claude OCR with Structured
  Outputs](https://n8layman.github.io/ohseer/articles/claude-structured-output.md):
